<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="ie=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><link rel=preload as=font href=https://www.gowrishankar.info/fonts/vendor/jost/jost-v4-latin-regular.woff2 type=font/woff2 crossorigin><link rel=preload as=font href=https://www.gowrishankar.info/fonts/vendor/jost/jost-v4-latin-700.woff2 type=font/woff2 crossorigin><link rel=stylesheet href=https://www.gowrishankar.info/main.196572c7a9a8fbfbb428b93dcfec37f1859256c6ec1a37a7408137df323b3240f708ba8f8c9aa0631a5630a7f05193abfa38328d9283c840bd207649a5418e34.css integrity="sha512-GWVyx6mo+/u0KLk9z+w38YWSVsbsGjenQIE33zI7MkD3CLqPjJqgYxpWMKfwUZOr+jgyjZKDyEC9IHZJpUGONA==" crossorigin=anonymous><noscript><style>img.lazyload{display:none}</style></noscript><meta name=robots content="index, follow"><meta name=googlebot content="index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1"><meta name=bingbot content="index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1"><title>Tensorflow 2: Introduction, Feature Engineering and Metrics - Gowri Shankar</title><meta name=description content="Introducing TF2 through Train, Test, Valid splitting, Imputation, Bias/Overfit handlers, One Hot Encoding, Embeddings, Tensor Slices, Keras APIs, metrics including accuracy, precision and ROC curve"><link rel=canonical href=https://www.gowrishankar.info/blog/tensorflow-2-introduction-feature-engineering-and-metrics/><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://www.gowrishankar.info/profile.png"><meta name=twitter:title content="Tensorflow 2: Introduction, Feature Engineering and Metrics"><meta name=twitter:description content="Introducing TF2 through Train, Test, Valid splitting, Imputation, Bias/Overfit handlers, One Hot Encoding, Embeddings, Tensor Slices, Keras APIs, metrics including accuracy, precision and ROC curve"><meta name=twitter:site content="@gowrishankarin"><meta name=twitter:creator content="@gowrishankarin"><meta property="og:title" content="Tensorflow 2: Introduction, Feature Engineering and Metrics"><meta property="og:description" content="Introducing TF2 through Train, Test, Valid splitting, Imputation, Bias/Overfit handlers, One Hot Encoding, Embeddings, Tensor Slices, Keras APIs, metrics including accuracy, precision and ROC curve"><meta property="og:type" content="article"><meta property="og:url" content="https://www.gowrishankar.info/blog/tensorflow-2-introduction-feature-engineering-and-metrics/"><meta property="og:image" content="https://www.gowrishankar.info/profile.png"><meta property="article:published_time" content="2020-04-04T09:19:42+01:00"><meta property="article:modified_time" content="2021-02-28T09:19:42+01:00"><meta property="og:site_name" content="Gowri Shankar"><meta property="article:publisher" content="https://www.facebook.com/verlinde.henk"><meta property="article:author" content="https://www.facebook.com/verlinde.henk"><meta property="og:locale" content="en_US"><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/www.gowrishankar.info\/blog\/tensorflow-2-introduction-feature-engineering-and-metrics\/"},"headline":"Tensorflow 2: Introduction, Feature Engineering and Metrics","image":[],"datePublished":"2020-04-04T09:19:42CET","dateModified":"2021-02-28T09:19:42CET","author":{"@type":"Organization","name":"Gowri Shankar"},"publisher":{"@type":"Organization","name":"Gowri Shankar","logo":{"@type":"ImageObject","url":"https:\/\/www.gowrishankar.info\/logo-doks.png"}},"description":"Introducing TF2 through Train, Test, Valid splitting, Imputation, Bias\/Overfit handlers, One Hot Encoding, Embeddings, Tensor Slices, Keras APIs, metrics including accuracy, precision and ROC curve"}</script><script type=application/ld+json>{"@context":"http://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Home","item":"https:\/\/www.gowrishankar.info\/"},{"@type":"ListItem","position":2,"name":"Blog","item":"https:\/\/www.gowrishankar.info\/blog\/"},{"@type":"ListItem","position":3,"name":"Tensorflow 2 Introduction Feature Engineering and Metrics","item":"https:\/\/www.gowrishankar.info\/blog\/tensorflow-2-introduction-feature-engineering-and-metrics\/"}]}</script><meta name=theme-color content="#fff"><link rel=apple-touch-icon sizes=180x180 href=https://www.gowrishankar.info/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=https://www.gowrishankar.info/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=https://www.gowrishankar.info/favicon-16x16.png><link rel=manifest href=https://www.gowrishankar.info/site.webmanifest><script type=text/javascript async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script><script type=text/x-mathjax-config>
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        processEscapes: true
      }
    });
</script></head><body class="blog single"><div class="header-bar fixed-top"></div><header class="navbar fixed-top navbar-expand-md navbar-light"><div class=container><input class="menu-btn order-0" type=checkbox id=menu-btn>
<label class="menu-icon d-md-none" for=menu-btn><span class=navicon></span></label><a class="navbar-brand order-1 order-md-0 mr-auto" href=https://www.gowrishankar.info/>Gowri Shankar</a>
<button id=mode class="btn btn-link order-2 order-md-4" type=button aria-label="Toggle mode">
<span class=toggle-dark><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-moon"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg></span><span class=toggle-light><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-sun"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></span></button><ul class="navbar-nav social-nav order-3 order-md-5"><li class=nav-item><a class=nav-link href=https://github.com/gowrishankarin><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-github"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77a5.44 5.44.0 00-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg><span class="ml-2 sr-only">GitHub</span></a></li></ul><div class="collapse navbar-collapse order-4 order-md-1"><ul class="navbar-nav main-nav mr-auto order-5 order-md-2"><li class=nav-item><a class=nav-link href=https://www.gowrishankar.info/docs/prologue/education/>Accolades</a></li><li class="nav-item active"><a class=nav-link href=https://www.gowrishankar.info/blog/>Blog</a></li><li class=nav-item><a class=nav-link href=https://www.gowrishankar.info/reads/>Bookshelf</a></li><li class=nav-item><a class=nav-link href=https://www.gowrishankar.info/contributors/gowri-shankar>Contact</a></li></ul><div class="break order-6 d-md-none"></div><form class="navbar-form flex-grow-1 order-7 order-md-3"><input id=userinput class="form-control is-search" type=search placeholder="Search docs..." aria-label="Search docs..." autocomplete=off><div id=suggestions class="shadow bg-white rounded"></div></form></div></div></header><div class="wrap container" role=document><div class=content><div class="row justify-content-left"><div class=col-12><article><div class=blog-header><h1>Tensorflow 2: Introduction, Feature Engineering and Metrics</h1><p><small>Posted April 4, 2020 by <a class="stretched-link position-relative" href=https://www.gowrishankar.info/contributors/gowri-shankar/>Gowri Shankar</a>&nbsp;&dash;&nbsp;<strong>27&nbsp;min read</strong></small><p></div><p class=lead>Introducing TF2 through Train, Test, Valid splitting, Imputation, Bias/Overfit handlers, One Hot Encoding, Embeddings, Tensor Slices, Keras APIs, metrics including accuracy, precision and ROC curve</p><h3 id=objective>Objective</h3><p>The key objective of this kernel is</p><ul><li>To introduce the new programming style for creating a neural network using Keras on TF2</li><li>One should be capable of starting Deep Learning without going through the conventional way of ML algorithms and landing here eventually. Ref:<a href=https://www.kaggle.com/gowrishankarin/learn-ml-ml101-rank-4500-to-450-in-a-day>Learn ML - ML101, Rank 4500 to ~450 in a day</a></li><li>Instill knowledge on key principles includes<ul><li>Train, Validation and Test data splitting</li><li>A simple mechanism to fill the missing values in the dataset</li><li>Bias and Overfit handlers like class weights and initial bias calculation</li><li>Handling categorical columns using One Hot Encoding or Embedding principles</li><li>Elegant way of creating dataset of tensor slices from pandas dataframes</li><li>Build a simple and flat a NN architecture using Keras</li><li>Predict the targets via predict functions</li><li>Analyse the results using various metrics include accuracy, precision, ROC curve etc</li></ul></li></ul><p>This is an attempt to make an engineer novice to expert on approach and process of building a neural network for classification problem.</p><div class=highlight><pre class=chroma><code class=language-python data-lang=python><span class=kn>from</span> <span class=nn>__future__</span> <span class=kn>import</span> <span class=n>absolute_import</span><span class=p>,</span> <span class=n>division</span><span class=p>,</span> <span class=n>print_function</span><span class=p>,</span> <span class=n>unicode_literals</span>

<span class=kn>import</span> <span class=nn>numpy</span> <span class=kn>as</span> <span class=nn>np</span>
<span class=kn>import</span> <span class=nn>pandas</span> <span class=kn>as</span> <span class=nn>pd</span>

<span class=kn>import</span> <span class=nn>tensorflow</span> <span class=kn>as</span> <span class=nn>tf</span>
<span class=kn>from</span> <span class=nn>sklearn.model_selection</span> <span class=kn>import</span> <span class=n>train_test_split</span>
</code></pre></div><h2 id=pre-processing>Pre-Processing</h2><h3 id=read-data>Read Data</h3><ul><li>Read the data from the data source using Pandas package.</li><li>We have 3 files - train.csv, test.csv and sample_submission.csv</li><li>Train set has 23 feature columns and 60,000 observations</li><li>Test set has 23 feature columns and 40,000 observations</li></ul><p>Hint:</p><ul><li>Test set volume is huge, there is a chance of imbalance target value. Ensure it is handled to avoid bias.</li><li>Also note, if the data is imbalanced - Right metrics is AUC(area under the curve) and not accuracy.</li></ul><div class=highlight><pre class=chroma><code class=language-python data-lang=python><span class=n>is_local</span> <span class=o>=</span> <span class=bp>False</span>
<span class=n>INPUT_DIR</span> <span class=o>=</span> <span class=s2>&#34;/kaggle/input/cat-in-the-dat-ii/&#34;</span>

<span class=kn>import</span> <span class=nn>tensorflow</span> <span class=kn>as</span> <span class=nn>tf</span><span class=p>;</span> 
<span class=k>print</span><span class=p>(</span><span class=n>tf</span><span class=o>.</span><span class=n>__version__</span><span class=p>)</span>

<span class=k>if</span><span class=p>(</span><span class=n>is_local</span><span class=p>):</span>
    <span class=n>INPUT_DIR</span> <span class=o>=</span> <span class=s2>&#34;../input/&#34;</span>

<span class=kn>import</span> <span class=nn>os</span>
<span class=k>for</span> <span class=n>dirname</span><span class=p>,</span> <span class=n>_</span><span class=p>,</span> <span class=n>filenames</span> <span class=ow>in</span> <span class=n>os</span><span class=o>.</span><span class=n>walk</span><span class=p>(</span><span class=n>INPUT_DIR</span><span class=p>):</span>
    <span class=k>for</span> <span class=n>filename</span> <span class=ow>in</span> <span class=n>filenames</span><span class=p>:</span>
        <span class=k>print</span><span class=p>(</span><span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>dirname</span><span class=p>,</span> <span class=n>filename</span><span class=p>))</span>

<span class=c1># Any results you write to the current directory are saved as output.</span>
</code></pre></div><pre><code>2.1.0
/kaggle/input/cat-in-the-dat-ii/train.csv
/kaggle/input/cat-in-the-dat-ii/test.csv
/kaggle/input/cat-in-the-dat-ii/sample_submission.csv
</code></pre><div class=highlight><pre class=chroma><code class=language-python data-lang=python><span class=n>train_df</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>read_csv</span><span class=p>(</span><span class=n>INPUT_DIR</span> <span class=o>+</span> <span class=s2>&#34;train.csv&#34;</span><span class=p>)</span>
<span class=n>test_df</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>read_csv</span><span class=p>(</span><span class=n>INPUT_DIR</span> <span class=o>+</span> <span class=s2>&#34;test.csv&#34;</span><span class=p>)</span>
<span class=n>submission_df</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>read_csv</span><span class=p>(</span><span class=n>INPUT_DIR</span> <span class=o>+</span> <span class=s2>&#34;sample_submission.csv&#34;</span><span class=p>)</span>
<span class=k>print</span><span class=p>(</span><span class=s2>&#34;Shape of the train data is &#34;</span><span class=p>,</span> <span class=n>train_df</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>
<span class=k>print</span><span class=p>(</span><span class=s2>&#34;Shape of the test data is &#34;</span><span class=p>,</span> <span class=n>test_df</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>

<span class=n>train_df</span><span class=o>.</span><span class=n>head</span><span class=p>()</span>
</code></pre></div><pre><code>Shape of the train data is  (600000, 25)
Shape of the test data is  (400000, 24)
</code></pre><div><style scoped>.dataframe tbody tr th:only-of-type{vertical-align:middle}<pre><code>.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</code></pre><p></style></p><table border=1 class=dataframe><thead><tr style=text-align:right><th></th><th>id</th><th>bin_0</th><th>bin_1</th><th>bin_2</th><th>bin_3</th><th>bin_4</th><th>nom_0</th><th>nom_1</th><th>nom_2</th><th>nom_3</th><th>...</th><th>nom_9</th><th>ord_0</th><th>ord_1</th><th>ord_2</th><th>ord_3</th><th>ord_4</th><th>ord_5</th><th>day</th><th>month</th><th>target</th></tr></thead><tbody><tr><th>0</th><td>0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>F</td><td>N</td><td>Red</td><td>Trapezoid</td><td>Hamster</td><td>Russia</td><td>...</td><td>02e7c8990</td><td>3.0</td><td>Contributor</td><td>Hot</td><td>c</td><td>U</td><td>Pw</td><td>6.0</td><td>3.0</td><td>0</td></tr><tr><th>1</th><td>1</td><td>1.0</td><td>1.0</td><td>0.0</td><td>F</td><td>Y</td><td>Red</td><td>Star</td><td>Axolotl</td><td>NaN</td><td>...</td><td>f37df64af</td><td>3.0</td><td>Grandmaster</td><td>Warm</td><td>e</td><td>X</td><td>pE</td><td>7.0</td><td>7.0</td><td>0</td></tr><tr><th>2</th><td>2</td><td>0.0</td><td>1.0</td><td>0.0</td><td>F</td><td>N</td><td>Red</td><td>NaN</td><td>Hamster</td><td>Canada</td><td>...</td><td>NaN</td><td>3.0</td><td>NaN</td><td>Freezing</td><td>n</td><td>P</td><td>eN</td><td>5.0</td><td>9.0</td><td>0</td></tr><tr><th>3</th><td>3</td><td>NaN</td><td>0.0</td><td>0.0</td><td>F</td><td>N</td><td>Red</td><td>Circle</td><td>Hamster</td><td>Finland</td><td>...</td><td>f9d456e57</td><td>1.0</td><td>Novice</td><td>Lava Hot</td><td>a</td><td>C</td><td>NaN</td><td>3.0</td><td>3.0</td><td>0</td></tr><tr><th>4</th><td>4</td><td>0.0</td><td>NaN</td><td>0.0</td><td>T</td><td>N</td><td>Red</td><td>Triangle</td><td>Hamster</td><td>Costa Rica</td><td>...</td><td>c5361037c</td><td>3.0</td><td>Grandmaster</td><td>Cold</td><td>h</td><td>C</td><td>OZ</td><td>5.0</td><td>12.0</td><td>0</td></tr></tbody></table><p>5 rows × 25 columns</p></div><h3 id=constants>Constants</h3><p>Let us initialize the constants</p><ul><li><strong>Embedding Dimensions:</strong> An embedding a low-dimensional space into which a high dimensional vector is represented.
It makes a large space of information into a sparse vectors.
Here we are randomly picking 9 dimensions to represent the sparse vector of certain features. More about embeddings below.</li><li><strong>Batch Size:</strong> Batch size tells the network, the number of observations to propagate through the networks. The key aspect of the batch size is
how quickly a model trains/learns.</li><li><strong>Epochs:</strong> Epoch is the number of times a learning algorithms is iterated on the entire training data set. ie Count of every observation in the training dataset
involved in the learning process of the model.</li><li><strong>Train and Validation Split:</strong> A model is better if it is generalized rather than work well for the given dataset. So the train dataset is split into train and validation data. During the training process, accuracy of the model is measured through validation data metrics rather than train.</li><li><strong>Metrics:</strong> We are observing 8 metrics to understand a model. Ref: <a href=https://www.kaggle.com/gowrishankarin/precision-recall-roc-auc-validation-metrics>Precision, Recall, ROC, AUC - Validation Metrics</a></li></ul><div class=highlight><pre class=chroma><code class=language-python data-lang=python><span class=n>EMBEDDING_DIMENSIONS</span><span class=o>=</span><span class=mi>9</span>
<span class=n>BATCH_SIZE</span> <span class=o>=</span> <span class=mi>1024</span>
<span class=n>EPOCHS</span> <span class=o>=</span> <span class=mi>25</span>
<span class=n>TRAIN_VAL_SPLIT_RATIO</span> <span class=o>=</span> <span class=mf>0.3</span>

<span class=n>METRICS</span> <span class=o>=</span> <span class=p>[</span>
    <span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>metrics</span><span class=o>.</span><span class=n>TruePositives</span><span class=p>(</span><span class=n>name</span><span class=o>=</span><span class=s1>&#39;tp&#39;</span><span class=p>),</span>
    <span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>metrics</span><span class=o>.</span><span class=n>FalsePositives</span><span class=p>(</span><span class=n>name</span><span class=o>=</span><span class=s1>&#39;fp&#39;</span><span class=p>),</span>
    <span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>metrics</span><span class=o>.</span><span class=n>TrueNegatives</span><span class=p>(</span><span class=n>name</span><span class=o>=</span><span class=s1>&#39;tn&#39;</span><span class=p>),</span>
    <span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>metrics</span><span class=o>.</span><span class=n>FalseNegatives</span><span class=p>(</span><span class=n>name</span><span class=o>=</span><span class=s1>&#39;fn&#39;</span><span class=p>),</span>
    <span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>metrics</span><span class=o>.</span><span class=n>BinaryAccuracy</span><span class=p>(</span><span class=n>name</span><span class=o>=</span><span class=s1>&#39;accuracy&#39;</span><span class=p>),</span>
    <span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>metrics</span><span class=o>.</span><span class=n>Precision</span><span class=p>(</span><span class=n>name</span><span class=o>=</span><span class=s1>&#39;precision&#39;</span><span class=p>),</span>
    <span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>metrics</span><span class=o>.</span><span class=n>Recall</span><span class=p>(</span><span class=n>name</span><span class=o>=</span><span class=s1>&#39;recall&#39;</span><span class=p>),</span>
    <span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>metrics</span><span class=o>.</span><span class=n>AUC</span><span class=p>(</span><span class=n>name</span><span class=o>=</span><span class=s1>&#39;auc&#39;</span><span class=p>),</span>
<span class=p>]</span>

</code></pre></div><h2 id=understanding-the-features>Understanding the Features</h2><p>Understanding the dataset by doing an <strong>Exploratory Data Analysis and Visualization</strong> brings significant insights for solving the problem. Ref: <a href=https://www.kaggle.com/gowrishankarin/interactive-eda-using-plotly>Interactive EDA using Plotly</a><br>In our dataset, we have 5 types of features</p><ul><li>Binary Data - Discrete (1, 0) or (True, False), (Yes, No)</li><li>Nominal Data - Discrete (Male, Female) or (Eye Colors) or (Hair Color)</li><li>Ordinal Data - Discrete Sequence (Hot, Hotter, Hottest) or (Scale of 1-10)</li><li>Cyclic Data - Continuous, Numeric (Weekdays) or (Month Dates)</li><li>Target Data - Our target data is a binary data</li></ul><div class=highlight><pre class=chroma><code class=language-python data-lang=python><span class=n>COLUMN_TYPES</span> <span class=o>=</span> <span class=p>{</span>
    <span class=s1>&#39;id&#39;</span><span class=p>:</span> <span class=s1>&#39;index&#39;</span><span class=p>,</span>
    <span class=s1>&#39;bin_0&#39;</span><span class=p>:</span> <span class=s1>&#39;binary&#39;</span><span class=p>,</span> <span class=s1>&#39;bin_1&#39;</span><span class=p>:</span> <span class=s1>&#39;binary&#39;</span><span class=p>,</span> <span class=s1>&#39;bin_2&#39;</span><span class=p>:</span> <span class=s1>&#39;binary&#39;</span><span class=p>,</span> <span class=s1>&#39;bin_3&#39;</span><span class=p>:</span> <span class=s1>&#39;binary&#39;</span><span class=p>,</span> 
    <span class=s1>&#39;bin_4&#39;</span><span class=p>:</span> <span class=s1>&#39;binary&#39;</span><span class=p>,</span> <span class=s1>&#39;nom_0&#39;</span><span class=p>:</span> <span class=s1>&#39;categorical&#39;</span><span class=p>,</span> <span class=s1>&#39;nom_1&#39;</span><span class=p>:</span> <span class=s1>&#39;categorical&#39;</span><span class=p>,</span>
    <span class=s1>&#39;nom_2&#39;</span><span class=p>:</span> <span class=s1>&#39;categorical&#39;</span><span class=p>,</span> <span class=s1>&#39;nom_3&#39;</span><span class=p>:</span> <span class=s1>&#39;categorical&#39;</span><span class=p>,</span> <span class=s1>&#39;nom_4&#39;</span><span class=p>:</span> <span class=s1>&#39;categorical&#39;</span><span class=p>,</span> 
    <span class=s1>&#39;nom_5&#39;</span><span class=p>:</span> <span class=s1>&#39;categorical&#39;</span><span class=p>,</span> <span class=s1>&#39;nom_6&#39;</span><span class=p>:</span> <span class=s1>&#39;categorical&#39;</span><span class=p>,</span> <span class=s1>&#39;nom_7&#39;</span><span class=p>:</span> <span class=s1>&#39;categorical&#39;</span><span class=p>,</span> 
    <span class=s1>&#39;nom_8&#39;</span><span class=p>:</span> <span class=s1>&#39;categorical&#39;</span><span class=p>,</span> <span class=s1>&#39;nom_9&#39;</span><span class=p>:</span> <span class=s1>&#39;categorical&#39;</span><span class=p>,</span>
    <span class=s1>&#39;ord_0&#39;</span><span class=p>:</span> <span class=s1>&#39;ordinal&#39;</span><span class=p>,</span> <span class=s1>&#39;ord_1&#39;</span><span class=p>:</span> <span class=s1>&#39;ordinal&#39;</span><span class=p>,</span> <span class=s1>&#39;ord_2&#39;</span><span class=p>:</span> <span class=s1>&#39;ordinal&#39;</span><span class=p>,</span> 
    <span class=s1>&#39;ord_3&#39;</span><span class=p>:</span> <span class=s1>&#39;ordinal&#39;</span><span class=p>,</span> <span class=s1>&#39;ord_4&#39;</span><span class=p>:</span> <span class=s1>&#39;ordinal&#39;</span><span class=p>,</span> <span class=s1>&#39;ord_5&#39;</span><span class=p>:</span> <span class=s1>&#39;ordinal&#39;</span><span class=p>,</span> 
    <span class=s1>&#39;day&#39;</span><span class=p>:</span> <span class=s1>&#39;cyclic&#39;</span><span class=p>,</span> <span class=s1>&#39;month&#39;</span><span class=p>:</span> <span class=s1>&#39;cyclic&#39;</span><span class=p>,</span>
    <span class=s1>&#39;target&#39;</span><span class=p>:</span> <span class=s1>&#39;target&#39;</span>
<span class=p>}</span>
</code></pre></div><h3 id=dealing-with-missing-data>Dealing with Missing Data</h3><p>The most time consuming aspect of a dataset is dealing with missing data. We are presenting a simple way to address with this</p><ul><li>All categorical and binary data are filled with a special value NaN</li><li>Cyclic data is filled with the median value for simplicity</li></ul><p>There are sophisticated imputation mechanisms available in sklearn packages. Ref: <a href=https://github.com/iskandr/fancyimpute>Fancy Impute</a>, <a href=https://scikit-learn.org/stable/modules/classes.html#module-sklearn.impute>sklearn.impute</a></p><div class=highlight><pre class=chroma><code class=language-python data-lang=python><span class=k>def</span> <span class=nf>fill_missing_values</span><span class=p>(</span><span class=n>dataframe</span><span class=p>,</span> <span class=n>ignore_cols</span><span class=o>=</span><span class=p>[</span><span class=s1>&#39;id&#39;</span><span class=p>,</span> <span class=s1>&#39;target&#39;</span><span class=p>]):</span>
    <span class=n>feature_cols</span> <span class=o>=</span> <span class=p>[</span><span class=n>column</span> <span class=k>for</span> <span class=n>column</span> <span class=ow>in</span> <span class=n>dataframe</span><span class=o>.</span><span class=n>columns</span> <span class=k>if</span> <span class=n>column</span> <span class=ow>not</span> <span class=ow>in</span> <span class=n>ignore_cols</span><span class=p>]</span>
    <span class=k>for</span> <span class=n>a_column</span> <span class=ow>in</span> <span class=n>feature_cols</span><span class=p>:</span>
        <span class=n>typee</span> <span class=o>=</span> <span class=n>COLUMN_TYPES</span><span class=p>[</span><span class=n>a_column</span><span class=p>]</span>
        <span class=k>if</span><span class=p>(</span><span class=n>typee</span> <span class=o>==</span> <span class=s1>&#39;binary&#39;</span><span class=p>):</span>
            <span class=n>dataframe</span><span class=o>.</span><span class=n>loc</span><span class=p>[:,</span> <span class=n>a_column</span><span class=p>]</span> <span class=o>=</span> <span class=n>dataframe</span><span class=o>.</span><span class=n>loc</span><span class=p>[:,</span> <span class=n>a_column</span><span class=p>]</span><span class=o>.</span><span class=n>astype</span><span class=p>(</span><span class=nb>str</span><span class=p>)</span><span class=o>.</span><span class=n>fillna</span><span class=p>(</span><span class=o>-</span><span class=mi>9999999</span><span class=p>)</span>
        <span class=k>elif</span><span class=p>(</span><span class=n>typee</span> <span class=o>==</span> <span class=s1>&#39;numeric&#39;</span><span class=p>):</span>
            <span class=k>pass</span>
        <span class=k>elif</span><span class=p>(</span><span class=n>typee</span> <span class=o>==</span> <span class=s1>&#39;categorical&#39;</span><span class=p>):</span>
            <span class=n>dataframe</span><span class=o>.</span><span class=n>loc</span><span class=p>[:,</span> <span class=n>a_column</span><span class=p>]</span> <span class=o>=</span> <span class=n>dataframe</span><span class=o>.</span><span class=n>loc</span><span class=p>[:,</span> <span class=n>a_column</span><span class=p>]</span><span class=o>.</span><span class=n>astype</span><span class=p>(</span><span class=nb>str</span><span class=p>)</span><span class=o>.</span><span class=n>fillna</span><span class=p>(</span><span class=o>-</span><span class=mi>9999999</span><span class=p>)</span>
        <span class=k>elif</span><span class=p>(</span><span class=n>typee</span> <span class=o>==</span> <span class=s1>&#39;ordinal&#39;</span><span class=p>):</span>
            <span class=n>dataframe</span><span class=o>.</span><span class=n>loc</span><span class=p>[:,</span> <span class=n>a_column</span><span class=p>]</span> <span class=o>=</span> <span class=n>dataframe</span><span class=o>.</span><span class=n>loc</span><span class=p>[:,</span> <span class=n>a_column</span><span class=p>]</span><span class=o>.</span><span class=n>astype</span><span class=p>(</span><span class=nb>str</span><span class=p>)</span><span class=o>.</span><span class=n>fillna</span><span class=p>(</span><span class=o>-</span><span class=mi>9999999</span><span class=p>)</span>
        <span class=k>elif</span><span class=p>(</span><span class=n>typee</span> <span class=o>==</span> <span class=s1>&#39;cyclic&#39;</span><span class=p>):</span>
            <span class=n>median_val</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>median</span><span class=p>(</span><span class=n>dataframe</span><span class=p>[</span><span class=n>a_column</span><span class=p>]</span><span class=o>.</span><span class=n>values</span><span class=p>)</span>
            <span class=k>if</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>isnan</span><span class=p>(</span><span class=n>median_val</span><span class=p>)):</span>
                <span class=n>median_val</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>median</span><span class=p>(</span><span class=n>dataframe</span><span class=p>[</span><span class=o>~</span><span class=n>np</span><span class=o>.</span><span class=n>isnan</span><span class=p>(</span><span class=n>dataframe</span><span class=p>[</span><span class=n>a_column</span><span class=p>])][</span><span class=n>a_column</span><span class=p>]</span><span class=o>.</span><span class=n>values</span><span class=p>)</span>
            <span class=k>print</span><span class=p>(</span><span class=n>a_column</span><span class=p>,</span> <span class=n>median_val</span><span class=p>)</span>
            <span class=n>dataframe</span><span class=o>.</span><span class=n>loc</span><span class=p>[:,</span> <span class=n>a_column</span><span class=p>]</span> <span class=o>=</span> <span class=n>dataframe</span><span class=o>.</span><span class=n>loc</span><span class=p>[:,</span> <span class=n>a_column</span><span class=p>]</span><span class=o>.</span><span class=n>astype</span><span class=p>(</span><span class=nb>float</span><span class=p>)</span><span class=o>.</span><span class=n>fillna</span><span class=p>(</span><span class=n>median_val</span><span class=p>)</span>
            
    <span class=k>return</span> <span class=n>dataframe</span><span class=o>.</span><span class=n>copy</span><span class=p>(</span><span class=n>deep</span><span class=o>=</span><span class=bp>True</span><span class=p>)</span>

<span class=n>train_df</span> <span class=o>=</span> <span class=n>fill_missing_values</span><span class=p>(</span><span class=n>train_df</span><span class=p>,</span> <span class=n>ignore_cols</span><span class=o>=</span><span class=p>[</span><span class=s1>&#39;id&#39;</span><span class=p>,</span> <span class=s1>&#39;target&#39;</span><span class=p>])</span>
<span class=n>test_df</span> <span class=o>=</span> <span class=n>fill_missing_values</span><span class=p>(</span><span class=n>test_df</span><span class=p>,</span> <span class=n>ignore_cols</span><span class=o>=</span><span class=p>[</span><span class=s1>&#39;id&#39;</span><span class=p>])</span>
</code></pre></div><pre><code>day 5.0
month 6.0
day 5.0
month 6.0
</code></pre><h2 id=bias-and-class-weights>Bias and Class Weights</h2><ul><li>Our goal is to avoid overfitting and generalization of the model we create.</li><li>As a first measure we split the data into train and validation set</li><li>Further we shall intervene by calculating initial bias and class weights</li><li>How to find imbalance in the target value<ul><li>Find the ratio of positive and negatives in the target distribution</li><li>In our dataset, we have 18.72 percent are positives and rest are negatives</li><li>We assume a similar behavior in the test dataset as well</li><li>However there is no guarantee that it will be true</li></ul></li></ul><h3 id=initial-bias>Initial Bias</h3><p>Since the dataset is imbalanced, our output layer to reflect the bias. Bias can be calculated as follows</p><p>\begin{equation*}
p_0 = \frac{pos}{pos + neg} = \frac{1}{1 + b^0} \<br>b_0 = - log_e(\frac{1}{p_0} - 1) \<br>b_0 = log_e(\frac{pos}{neg})
\end{equation*}</p><p>With this inialization, Initial loss/cost function or <strong>cross entropy</strong></p><div align=center style=font-size:18px>Loss/Cost Function or Cross Entropy</div><br><p>\begin{equation*}</p><ul><li>p_0 log(p_0) - (1 - p_0) log(1 - p_0)
\end{equation*}</li></ul><div class=highlight><pre class=chroma><code class=language-python data-lang=python><span class=k>def</span> <span class=nf>get_initial_bias</span><span class=p>(</span><span class=n>df</span><span class=p>,</span> <span class=n>col_name</span><span class=o>=</span><span class=s1>&#39;target&#39;</span><span class=p>):</span>
    <span class=n>neg</span><span class=p>,</span> <span class=n>pos</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>bincount</span><span class=p>(</span><span class=n>df</span><span class=p>[</span><span class=n>col_name</span><span class=p>])</span>
    <span class=n>total</span> <span class=o>=</span> <span class=n>neg</span> <span class=o>+</span> <span class=n>pos</span>
    <span class=k>print</span><span class=p>(</span><span class=s1>&#39;Examples:</span><span class=se>\n</span><span class=s1>    Total: {}</span><span class=se>\n</span><span class=s1>    Positive: {} ({:.2f}</span><span class=si>% o</span><span class=s1>f total)</span><span class=se>\n</span><span class=s1>&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span>
        <span class=n>total</span><span class=p>,</span> <span class=n>pos</span><span class=p>,</span> <span class=mi>100</span> <span class=o>*</span> <span class=n>pos</span> <span class=o>/</span> <span class=n>total</span><span class=p>))</span>

    <span class=n>initial_bias</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>log</span><span class=p>([</span><span class=n>pos</span><span class=o>/</span><span class=n>neg</span><span class=p>])</span>
    
    <span class=k>return</span> <span class=n>initial_bias</span>



<span class=n>initial_bias</span> <span class=o>=</span> <span class=n>get_initial_bias</span><span class=p>(</span><span class=n>train_df</span><span class=p>)</span>

</code></pre></div><pre><code>Examples:
    Total: 600000
    Positive: 112323 (18.72% of total)
</code></pre><h3 id=class-weights>Class Weights</h3><ul><li>The idea is to have the model heavily weight the few positive option available for training.</li><li>This is done using &ldquo;class_weight&rdquo; param of the model to pay more attention towards under represented class.</li><li>Incorporation of class weights is made aware through the cost function</li><li>The loss/cost function discussed earlier transform as follows</li></ul><div align=center style=font-size:18px>Weighted Cost Entropy</div><br><p>\begin{equation*}</p><ul><li>w_0 p_0 log(p_0) - w1 (1 - p_0) log(1 - p_0)
\end{equation*}</li></ul><div class=highlight><pre class=chroma><code class=language-python data-lang=python><span class=k>def</span> <span class=nf>get_class_weights</span><span class=p>(</span><span class=n>df</span><span class=p>,</span> <span class=n>col_name</span><span class=o>=</span><span class=s1>&#39;target&#39;</span><span class=p>):</span>
    <span class=n>neg</span><span class=p>,</span> <span class=n>pos</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>bincount</span><span class=p>(</span><span class=n>df</span><span class=p>[</span><span class=n>col_name</span><span class=p>])</span>
    <span class=n>weight_for_0</span> <span class=o>=</span> <span class=p>(</span><span class=mi>1</span> <span class=o>/</span> <span class=n>neg</span><span class=p>)</span> <span class=o>*</span> <span class=p>(</span><span class=n>neg</span> <span class=o>+</span> <span class=n>pos</span><span class=p>)</span> <span class=o>/</span> <span class=mf>2.0</span>
    <span class=n>weight_for_1</span> <span class=o>=</span> <span class=p>(</span><span class=mi>1</span> <span class=o>/</span> <span class=n>pos</span><span class=p>)</span> <span class=o>*</span> <span class=p>(</span><span class=n>neg</span> <span class=o>+</span> <span class=n>pos</span><span class=p>)</span> <span class=o>/</span> <span class=mf>2.0</span>

    <span class=n>class_weight</span> <span class=o>=</span> <span class=p>{</span>
        <span class=mi>0</span><span class=p>:</span> <span class=n>weight_for_0</span><span class=p>,</span>
        <span class=mi>1</span><span class=p>:</span> <span class=n>weight_for_1</span>
    <span class=p>}</span>

    <span class=k>print</span><span class=p>(</span><span class=s2>&#34;Class 0: &#34;</span><span class=p>,</span> <span class=n>weight_for_0</span><span class=p>,</span> <span class=s2>&#34;Weightage&#34;</span><span class=p>)</span>
    <span class=k>print</span><span class=p>(</span><span class=s2>&#34;Class 1: &#34;</span><span class=p>,</span> <span class=n>weight_for_1</span><span class=p>,</span> <span class=s2>&#34;Weightage&#34;</span><span class=p>)</span>
    
    <span class=k>return</span> <span class=n>class_weight</span>

<span class=n>class_weight</span> <span class=o>=</span> <span class=n>get_class_weights</span><span class=p>(</span><span class=n>train_df</span><span class=p>)</span>
</code></pre></div><pre><code>Class 0:  0.6151612645254954 Weightage
Class 1:  2.6708688336315802 Weightage
</code></pre><h2 id=stratified-split-of-train-and-validation-data>Stratified Split of Train and Validation Data</h2><p>To avoid Sampling bias, we shall split the data using Stratification. Stratified split ensure the imbalance ratio is maintained in train and validation dataset.</p><p>What is Sampling Bias?<br>When some members of the population have lower sampling probability than others, a sampling bias occurs.
It results in samples favoring a particular group of the population and the model end up with bias.</p><div class=highlight><pre class=chroma><code class=language-python data-lang=python><span class=c1>### Stratified Split</span>

<span class=kn>from</span> <span class=nn>sklearn.model_selection</span> <span class=kn>import</span> <span class=n>StratifiedShuffleSplit</span>

<span class=k>def</span> <span class=nf>split_train_validation_data</span><span class=p>(</span><span class=n>df</span><span class=p>,</span> <span class=n>col_name</span><span class=o>=</span><span class=s1>&#39;target&#39;</span><span class=p>,</span> <span class=n>stratify</span><span class=o>=</span><span class=bp>True</span><span class=p>,</span> <span class=n>test_size</span><span class=o>=</span><span class=mf>0.3</span><span class=p>):</span>
    <span class=n>train</span> <span class=o>=</span> <span class=bp>None</span>
    <span class=n>val</span> <span class=o>=</span> <span class=bp>None</span>
    
    <span class=k>if</span><span class=p>(</span><span class=n>stratify</span><span class=p>):</span>
        

        <span class=n>sss</span> <span class=o>=</span> <span class=n>StratifiedShuffleSplit</span><span class=p>(</span><span class=n>n_splits</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>test_size</span><span class=o>=</span><span class=mf>0.2</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>21</span><span class=p>)</span>
        <span class=n>sss</span><span class=o>.</span><span class=n>get_n_splits</span><span class=p>(</span><span class=n>df</span><span class=p>,</span> <span class=n>df</span><span class=o>.</span><span class=n>target</span><span class=p>)</span>

        <span class=n>splits</span> <span class=o>=</span> <span class=n>sss</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=n>df</span><span class=p>,</span> <span class=n>df</span><span class=o>.</span><span class=n>target</span><span class=p>)</span> 
        
        <span class=n>indices</span> <span class=o>=</span> <span class=p>[]</span>
        <span class=k>for</span> <span class=n>train_index</span><span class=p>,</span> <span class=n>test_index</span> <span class=ow>in</span> <span class=n>splits</span><span class=p>:</span>
            <span class=n>indices</span><span class=o>.</span><span class=n>append</span><span class=p>({</span>
                <span class=s1>&#39;train&#39;</span><span class=p>:</span> <span class=n>train_index</span><span class=p>,</span>
                <span class=s1>&#39;test&#39;</span><span class=p>:</span> <span class=n>test_index</span>
            <span class=p>})</span>

        <span class=n>train</span> <span class=o>=</span> <span class=n>df</span><span class=o>.</span><span class=n>iloc</span><span class=p>[</span><span class=n>indices</span><span class=p>[</span><span class=mi>0</span><span class=p>][</span><span class=s1>&#39;train&#39;</span><span class=p>]]</span>
        <span class=n>val</span> <span class=o>=</span> <span class=n>df</span><span class=o>.</span><span class=n>iloc</span><span class=p>[</span><span class=n>indices</span><span class=p>[</span><span class=mi>0</span><span class=p>][</span><span class=s1>&#39;test&#39;</span><span class=p>]]</span>
        
    <span class=k>else</span><span class=p>:</span>
        <span class=n>train</span><span class=p>,</span> <span class=n>val</span> <span class=o>=</span> <span class=n>train_test_split</span><span class=p>(</span><span class=n>train_df</span><span class=p>,</span> <span class=n>test_size</span><span class=o>=</span><span class=n>test_size</span><span class=p>)</span>
    <span class=k>return</span> <span class=n>train</span><span class=p>,</span> <span class=n>val</span>

<span class=n>train</span><span class=p>,</span> <span class=n>val</span> <span class=o>=</span> <span class=n>split_train_validation_data</span><span class=p>(</span><span class=n>train_df</span><span class=p>,</span> <span class=n>test_size</span><span class=o>=</span><span class=n>TRAIN_VAL_SPLIT_RATIO</span><span class=p>)</span>
</code></pre></div><div class=highlight><pre class=chroma><code class=language-python data-lang=python><span class=n>get_initial_bias</span><span class=p>(</span><span class=n>train</span><span class=p>)</span>
<span class=n>get_initial_bias</span><span class=p>(</span><span class=n>val</span><span class=p>)</span>

</code></pre></div><pre><code>Examples:
    Total: 480000
    Positive: 89858 (18.72% of total)

Examples:
    Total: 120000
    Positive: 22465 (18.72% of total)






array([-1.46825275])
</code></pre><h2 id=tensorflow-2---feature-columns>Tensorflow 2 - Feature Columns</h2><ul><li>Tensorflow feature columns are the most awesome capability released recently</li><li>Feature columns are the bridge between raw data and the neural network operated data</li><li>What kind of data a NN will operate on - Numbers, mostly floating point numbers</li><li>How to translate the categorical columns like the few we discussed earlier. eg Color of eye, Gender, All retail shops of a market etc</li><li>The rich nature of feature columns enable one to transform diverse range of raw format to NN operatable format</li><li>Naturally, the output of the feature column becomes the input to the model.</li></ul><h2 id=one-hot-encoding>One Hot Encoding</h2><ul><li>For Categorical features, transformation of non-number data to number data is the goal</li><li>Categorical variables are nominal, The process of transforming into binary value is One Hot Encoding</li><li>The raw data in long format is converted into wide format</li><li>It is nothing but, binarization of a categorical values</li></ul><table><thead><tr><th style=text-align:center>Company</th><th style=text-align:center>Rank</th><th style=text-align:center>Price</th><th style=text-align:center></th><th style=text-align:center></th></tr></thead><tbody><tr><td style=text-align:center>VW</td><td style=text-align:center>4</td><td style=text-align:center></td><td style=text-align:center>100</td><td style=text-align:center></td></tr><tr><td style=text-align:center>Honda</td><td style=text-align:center>2</td><td style=text-align:center></td><td style=text-align:center>10000</td><td style=text-align:center></td></tr><tr><td style=text-align:center>Ford</td><td style=text-align:center>3</td><td style=text-align:center></td><td style=text-align:center>1000</td><td style=text-align:center></td></tr><tr><td style=text-align:center>Tesla</td><td style=text-align:center>1</td><td style=text-align:center></td><td style=text-align:center>100000</td><td style=text-align:center></td></tr></tbody></table><div align=center style=font-size:30px>TO</div><table><thead><tr><th style=text-align:center>Company</th><th style=text-align:center>Rank 1</th><th style=text-align:center>Rank 2</th><th style=text-align:center>Rank 3</th><th style=text-align:center>Rank 4</th><th style=text-align:center>Price</th></tr></thead><tbody><tr><td style=text-align:center>VW</td><td style=text-align:center>0</td><td style=text-align:center>0</td><td style=text-align:center>0</td><td style=text-align:center>1</td><td style=text-align:center>100</td></tr><tr><td style=text-align:center>Honda</td><td style=text-align:center>0</td><td style=text-align:center>1</td><td style=text-align:center>0</td><td style=text-align:center>0</td><td style=text-align:center>10000</td></tr><tr><td style=text-align:center>Ford</td><td style=text-align:center>0</td><td style=text-align:center>0</td><td style=text-align:center>1</td><td style=text-align:center>0</td><td style=text-align:center>1000</td></tr><tr><td style=text-align:center>Tesla</td><td style=text-align:center>1</td><td style=text-align:center>0</td><td style=text-align:center>0</td><td style=text-align:center>0</td><td style=text-align:center>100000</td></tr></tbody></table><h2 id=embeddings>Embeddings</h2><ul><li>Another popular scheme used for transformation of categorical variables into numbers is embeddings.</li><li>This scheme represents discrete values as continuous vectors</li><li>This process for machine translation yields significan improvement to the model performance</li><li>In an NN, embeddings are low-dimensional continuous vectors</li><li>The reduction of dimensionality of a categorical variable and meaningful representation in the transformed space is the goal</li><li>Dimensionality reduction addresses the high cardinality of the categorical value</li><li>Embeddings place the similar things closer in the embedding space</li></ul><p>Examples</p><ol><li>Books on Data Science: Let us say there are 20000 books covering the wide gamut of all data science problems. Actual number of dimension here is 2000. By reducing the dimensonality of the dataset, From 20000 to 200 - We can represent the whole dataset.</li><li>Retail Outlets of a Country: Let us say there are 1.2 million retail outlets present in a country. 1000 odd number can represent the characteristics can represent the attributes of every outlet.</li></ol><p><strong>Representation of Embedding with 2 vectors</strong></p><pre><code>
shops = ["Sainsbury", "Tesco", "Reliance", "Lulu", "Costco"]  
embeddings = [
    [ 0.11, 0.52],  
    [0.32, 0.56], 
    [-0.56, -0.91], 
    [-0.21, 0.21]
]
</code></pre><p>Here we reduced the dimensionality to 2 from 5 to represent the property of a variable</p><h3 id=numeric-columns>Numeric Columns</h3><p>Numeric columns are pretty straight forword where the raw data is already with numeric value. Feature columns of TF2&rsquo;s numeric_column api comes handy to address the problem</p><h3 id=random-decisions>Random Decisions</h3><ul><li>If the variation is less than 100 on the categorical columns, One Hot Encoding taken in this code</li><li>Beyond 100 variation, Embeddings are preferred</li></ul><div class=highlight><pre class=chroma><code class=language-python data-lang=python><span class=k>def</span> <span class=nf>handle_feature_columns</span><span class=p>(</span><span class=n>df</span><span class=p>,</span> <span class=n>columns_to_remove</span><span class=o>=</span><span class=p>[</span><span class=s1>&#39;id&#39;</span><span class=p>,</span> <span class=s1>&#39;target&#39;</span><span class=p>],</span> <span class=n>all_categorical_as_ohe</span><span class=o>=</span><span class=bp>True</span><span class=p>):</span>
    
    <span class=k>def</span> <span class=nf>demo</span><span class=p>(</span><span class=n>feature_column</span><span class=p>):</span>
        <span class=n>feature_layer</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>layers</span><span class=o>.</span><span class=n>DenseFeatures</span><span class=p>(</span><span class=n>feature_column</span><span class=p>)</span>
    
    <span class=k>def</span> <span class=nf>one_hot_encode</span><span class=p>(</span><span class=n>col_name</span><span class=p>,</span> <span class=n>unique_values</span><span class=p>):</span>
        <span class=n>from_vocab</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>feature_column</span><span class=o>.</span><span class=n>categorical_column_with_vocabulary_list</span><span class=p>(</span>
            <span class=n>col_name</span><span class=p>,</span> <span class=n>unique_values</span>
        <span class=p>)</span>
        <span class=n>ohe</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>feature_column</span><span class=o>.</span><span class=n>indicator_column</span><span class=p>(</span><span class=n>from_vocab</span><span class=p>)</span>
        <span class=n>data</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>ohe</span><span class=p>)</span>
        <span class=n>demo</span><span class=p>(</span><span class=n>ohe</span><span class=p>)</span>
    
    <span class=k>def</span> <span class=nf>embedd</span><span class=p>(</span><span class=n>col_name</span><span class=p>,</span> <span class=n>unique_values</span><span class=p>):</span>
        <span class=n>from_vocab</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>feature_column</span><span class=o>.</span><span class=n>categorical_column_with_vocabulary_list</span><span class=p>(</span>
            <span class=n>col_name</span><span class=p>,</span> <span class=n>unique_values</span>
        <span class=p>)</span>
        <span class=n>embeddings</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>feature_column</span><span class=o>.</span><span class=n>embedding_column</span><span class=p>(</span><span class=n>from_vocab</span><span class=p>,</span> <span class=n>dimension</span><span class=o>=</span><span class=n>EMBEDDING_DIMENSIONS</span><span class=p>)</span>
        <span class=n>data</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>embeddings</span><span class=p>)</span>
        <span class=n>demo</span><span class=p>(</span><span class=n>embeddings</span><span class=p>)</span>
        
    <span class=k>def</span> <span class=nf>numeric</span><span class=p>(</span><span class=n>col_name</span><span class=p>,</span> <span class=n>unique_values</span><span class=p>):</span>
        <span class=n>from_numeric</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>feature_column</span><span class=o>.</span><span class=n>numeric_column</span><span class=p>(</span>
            <span class=n>col_name</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>tf</span><span class=o>.</span><span class=n>float32</span>
        <span class=p>)</span>
        <span class=n>data</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>from_numeric</span><span class=p>)</span>
        <span class=n>demo</span><span class=p>(</span><span class=n>from_numeric</span><span class=p>)</span>
    
    <span class=n>dataframe</span> <span class=o>=</span> <span class=n>df</span><span class=o>.</span><span class=n>copy</span><span class=p>()</span>
    <span class=k>for</span> <span class=n>pop_col</span> <span class=ow>in</span> <span class=n>columns_to_remove</span><span class=p>:</span>
        <span class=n>dataframe</span><span class=o>.</span><span class=n>pop</span><span class=p>(</span><span class=n>pop_col</span><span class=p>)</span>
    <span class=n>data</span> <span class=o>=</span> <span class=p>[]</span>
    
    <span class=k>for</span> <span class=n>a_column</span> <span class=ow>in</span> <span class=n>dataframe</span><span class=o>.</span><span class=n>columns</span><span class=p>:</span>
        <span class=n>typee</span> <span class=o>=</span> <span class=n>COLUMN_TYPES</span><span class=p>[</span><span class=n>a_column</span><span class=p>]</span>
        <span class=n>nunique</span> <span class=o>=</span> <span class=n>dataframe</span><span class=p>[</span><span class=n>a_column</span><span class=p>]</span><span class=o>.</span><span class=n>nunique</span><span class=p>()</span>
        <span class=n>unique_values</span> <span class=o>=</span> <span class=n>dataframe</span><span class=p>[</span><span class=n>a_column</span><span class=p>]</span><span class=o>.</span><span class=n>unique</span><span class=p>()</span>
        <span class=k>print</span><span class=p>(</span><span class=s1>&#39;Column :&#39;</span><span class=p>,</span> <span class=n>a_column</span><span class=p>,</span> <span class=n>nunique</span><span class=p>,</span> <span class=n>unique_values</span><span class=p>[:</span><span class=mi>10</span><span class=p>])</span>                
        <span class=k>if</span><span class=p>(</span><span class=n>typee</span> <span class=o>==</span> <span class=s1>&#39;binary&#39;</span><span class=p>):</span>
            <span class=n>one_hot_encode</span><span class=p>(</span><span class=n>a_column</span><span class=p>,</span> <span class=n>unique_values</span><span class=p>)</span>
        <span class=k>elif</span><span class=p>(</span><span class=n>typee</span> <span class=o>==</span> <span class=s1>&#39;cyclic&#39;</span><span class=p>):</span>
            <span class=n>numeric</span><span class=p>(</span><span class=n>a_column</span><span class=p>,</span> <span class=n>unique_values</span><span class=p>)</span>
            
        <span class=k>else</span><span class=p>:</span>
            <span class=k>if</span><span class=p>(</span><span class=n>all_categorical_as_ohe</span><span class=p>):</span>
                <span class=n>one_hot_encode</span><span class=p>(</span><span class=n>a_column</span><span class=p>,</span> <span class=n>unique_values</span><span class=p>)</span>
            <span class=k>else</span><span class=p>:</span>
                <span class=k>if</span><span class=p>(</span><span class=n>typee</span> <span class=o>==</span> <span class=s1>&#39;categorical&#39;</span><span class=p>):</span>
                    <span class=k>if</span><span class=p>(</span><span class=n>nunique</span> <span class=o>&lt;</span> <span class=mi>100</span><span class=p>):</span>
                        <span class=n>one_hot_encode</span><span class=p>(</span><span class=n>a_column</span><span class=p>,</span> <span class=n>unique_values</span><span class=p>)</span>
                    <span class=k>else</span><span class=p>:</span>
                        <span class=n>embedd</span><span class=p>(</span><span class=n>a_column</span><span class=p>,</span> <span class=n>unique_values</span><span class=p>)</span>
                <span class=k>elif</span><span class=p>(</span><span class=n>typee</span> <span class=o>==</span> <span class=s1>&#39;ordinal&#39;</span><span class=p>):</span>
                    <span class=n>embedd</span><span class=p>(</span><span class=n>a_column</span><span class=p>,</span> <span class=n>unique_values</span><span class=p>)</span>
            
    <span class=k>return</span> <span class=n>data</span>
</code></pre></div><div class=highlight><pre class=chroma><code class=language-python data-lang=python><span class=n>feature_columns</span> <span class=o>=</span> <span class=n>handle_feature_columns</span><span class=p>(</span><span class=n>train</span><span class=p>,</span> <span class=n>all_categorical_as_ohe</span><span class=o>=</span><span class=bp>False</span><span class=p>)</span>
</code></pre></div><pre><code>Column : bin_0 3 ['nan' '0.0' '1.0']
Column : bin_1 3 ['nan' '0.0' '1.0']
Column : bin_2 3 ['0.0' '1.0' 'nan']
Column : bin_3 3 ['F' 'T' 'nan']
Column : bin_4 3 ['nan' 'N' 'Y']
Column : nom_0 4 ['Red' 'Green' 'Blue' 'nan']
Column : nom_1 7 ['Polygon' 'Triangle' 'Trapezoid' 'Square' 'Circle' 'nan' 'Star']
Column : nom_2 7 ['Hamster' 'Axolotl' 'nan' 'Cat' 'Lion' 'Dog' 'Snake']
Column : nom_3 7 ['Russia' 'India' 'Costa Rica' 'Finland' 'China' 'Canada' 'nan']
Column : nom_4 5 ['Bassoon' 'Theremin' 'Piano' 'Oboe' 'nan']
Column : nom_5 1221 ['a256e9af4' '92fe4617b' '540b0e83b' 'ef8280dc7' 'cff330adf' '0664ab302'
 '7fa2dc49f' '08ab6d513' '9e2b2d267' 'a7d8c3224']
Column : nom_6 1518 ['b1a44e651' '688e92338' 'c8dbebb84' '62489fe7b' '5a8141d0e' 'a54000801'
 '7327dbe21' '69ca248d6' 'b3c631ddb' 'd5007ac35']
Column : nom_7 223 ['ba9faf5b1' 'bc9cc2a94' 'cf84cbe77' 'f313d1e52' '580231f65' '83bdea3a5'
 'a7059911d' '8781919c2' 'cb47f665d' 'd8c3cfd78']
Column : nom_8 223 ['95414620e' '45121db5e' 'd48e8b7af' 'nan' 'b42763706' '43e0ac7a1'
 '9789d425f' 'c9bbbb717' '798ccea46' '5859a8a06']
Column : nom_9 2218 ['nan' '51909bae5' 'bba491958' 'c44ea5ea9' 'b813f2af5' '1ccbcbdc7'
 '146bbb38b' '07d718459' '1d54b2cc1' '0b5e0c54c']
Column : ord_0 4 ['1.0' '2.0' 'nan' '3.0']
Column : ord_1 6 ['Master' 'Novice' 'Contributor' 'Grandmaster' 'nan' 'Expert']
Column : ord_2 7 ['Warm' 'Lava Hot' 'Freezing' 'Cold' 'Hot' 'Boiling Hot' 'nan']
Column : ord_3 16 ['e' 'h' 'd' 'i' 'c' 'n' 'o' 'f' 'b' 'a']
Column : ord_4 27 ['R' 'K' 'P' 'M' 'N' 'A' 'Q' 'H' 'D' 'T']
Column : ord_5 191 ['ok' 'Ib' 'Rv' 'TL' 'hG' 'hT' 'aE' 'MX' 'gc' 'Ji']
Column : day 7 [5. 3. 1. 7. 2. 6. 4.]
Column : month 12 [ 7.  4. 10.  8.  3.  9. 12.  5.  1.  2.]
</code></pre><h3 id=data-preparation>Data Preparation</h3><p>Tensors are the centrol data types for a Tensorflow NN framework. Crafting a tensors for the feature columns ensures the raw data translation into model acceptable one.
Simply speaking, a tensor is a multi-dimensional numerical array. To get full picture of a tensor, we have to understand few key words</p><ul><li><strong>Rank:</strong> Number of dimension of a tensor is its Rank.</li><li><strong>Shape:</strong> Shape of a tenser is its count of rows and columns.<ul><li>A rank zero tensor is a single number or it is a <strong>scalar</strong></li><li>A rank one tensor is an array of numbers or it is called as <strong>vector</strong></li><li>A rank two tensor is a matrix of numers or it has rows and columns</li></ul></li><li><strong>Tensor Slice:</strong> A tensor slice is a portion of data from the population based the batch size given</li></ul><div class=highlight><pre class=chroma><code class=language-python data-lang=python><span class=n>y_train</span> <span class=o>=</span> <span class=n>train</span><span class=o>.</span><span class=n>pop</span><span class=p>(</span><span class=s1>&#39;target&#39;</span><span class=p>)</span>
<span class=n>y_val</span> <span class=o>=</span> <span class=n>val</span><span class=o>.</span><span class=n>pop</span><span class=p>(</span><span class=s1>&#39;target&#39;</span><span class=p>)</span>
</code></pre></div><div class=highlight><pre class=chroma><code class=language-python data-lang=python><span class=k>def</span> <span class=nf>df_to_dataset</span><span class=p>(</span><span class=n>dataframe</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>shuffle</span><span class=o>=</span><span class=bp>True</span><span class=p>,</span> <span class=n>batch_size</span><span class=o>=</span><span class=mi>32</span><span class=p>,</span> <span class=n>is_test_data</span><span class=o>=</span><span class=bp>False</span><span class=p>):</span>
    <span class=n>dataframe</span> <span class=o>=</span> <span class=n>dataframe</span><span class=o>.</span><span class=n>copy</span><span class=p>()</span>
    <span class=n>ds</span> <span class=o>=</span> <span class=bp>None</span>
    <span class=k>if</span><span class=p>(</span><span class=n>is_test_data</span><span class=p>):</span>
        <span class=n>ds</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>Dataset</span><span class=o>.</span><span class=n>from_tensor_slices</span><span class=p>(</span><span class=nb>dict</span><span class=p>(</span><span class=n>dataframe</span><span class=p>))</span>
    <span class=k>else</span><span class=p>:</span>
        
        <span class=n>ds</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>Dataset</span><span class=o>.</span><span class=n>from_tensor_slices</span><span class=p>((</span><span class=nb>dict</span><span class=p>(</span><span class=n>dataframe</span><span class=p>),</span> <span class=n>y</span><span class=p>))</span>
        <span class=k>if</span><span class=p>(</span><span class=n>shuffle</span><span class=p>):</span>
            <span class=n>ds</span> <span class=o>=</span> <span class=n>ds</span><span class=o>.</span><span class=n>shuffle</span><span class=p>(</span><span class=n>buffer_size</span><span class=o>=</span><span class=nb>len</span><span class=p>(</span><span class=n>dataframe</span><span class=p>))</span>
    <span class=n>ds</span> <span class=o>=</span> <span class=n>ds</span><span class=o>.</span><span class=n>batch</span><span class=p>(</span><span class=n>batch_size</span><span class=p>)</span>
    <span class=k>return</span> <span class=n>ds</span>

<span class=n>train_ds</span> <span class=o>=</span> <span class=n>df_to_dataset</span><span class=p>(</span><span class=n>train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>,</span> <span class=n>shuffle</span><span class=o>=</span><span class=bp>False</span><span class=p>,</span> <span class=n>batch_size</span><span class=o>=</span><span class=n>BATCH_SIZE</span><span class=p>)</span>
<span class=n>val_ds</span> <span class=o>=</span> <span class=n>df_to_dataset</span><span class=p>(</span><span class=n>val</span><span class=p>,</span> <span class=n>y_val</span><span class=p>,</span> <span class=n>shuffle</span><span class=o>=</span><span class=bp>False</span><span class=p>,</span> <span class=n>batch_size</span><span class=o>=</span><span class=n>BATCH_SIZE</span><span class=p>)</span>
<span class=n>test_ds</span> <span class=o>=</span> <span class=n>df_to_dataset</span><span class=p>(</span><span class=n>test_df</span><span class=p>,</span> <span class=bp>None</span><span class=p>,</span> <span class=n>shuffle</span><span class=o>=</span><span class=bp>False</span><span class=p>,</span> <span class=n>batch_size</span><span class=o>=</span><span class=n>BATCH_SIZE</span><span class=p>,</span> <span class=n>is_test_data</span><span class=o>=</span><span class=bp>True</span><span class=p>)</span>
</code></pre></div><h2 id=model-training-and-prediction>Model, Training and Prediction</h2><p>Once the dataset is ready, a model is created, trained and evaluated.
The current model has 6 unique items stacked one after another&mldr; {WIP}</p><ul><li><strong>Sequential Model:</strong></li><li><strong>Feature Layer:</strong></li><li><strong>Dense Layer:</strong></li><li><strong>Batch Normalization:</strong></li><li><strong>Dropouts:</strong></li><li><strong>Activation Function - Relu:</strong></li><li><strong>Activation Function - Sigmoid:</strong></li><li><strong>Loss Function: Binary Cross Entropy:</strong></li><li><strong>From Logits:</strong></li><li><strong>Optimizer - Adam:</strong></li></ul><div class=highlight><pre class=chroma><code class=language-python data-lang=python><span class=k>def</span> <span class=nf>create_silly_model_2</span><span class=p>(</span><span class=n>feature_layer</span><span class=p>,</span> <span class=n>initial_bias</span><span class=o>=</span><span class=bp>None</span><span class=p>):</span>
    <span class=n>bias</span> <span class=o>=</span> <span class=bp>None</span>
    <span class=k>if</span><span class=p>(</span><span class=n>initial_bias</span><span class=p>):</span>
        <span class=n>bias</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>initializers</span><span class=o>.</span><span class=n>Constant</span><span class=p>(</span><span class=n>initial_bias</span><span class=p>)</span>
        
    <span class=n>model</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>Sequential</span><span class=p>([</span>
        <span class=n>feature_layer</span><span class=p>,</span>
        <span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>layers</span><span class=o>.</span><span class=n>Dense</span><span class=p>(</span><span class=mi>512</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s1>&#39;relu&#39;</span><span class=p>),</span>
        <span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>layers</span><span class=o>.</span><span class=n>Dropout</span><span class=p>(</span><span class=mf>0.3</span><span class=p>),</span>
        <span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>layers</span><span class=o>.</span><span class=n>BatchNormalization</span><span class=p>(),</span>
        <span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>layers</span><span class=o>.</span><span class=n>Dense</span><span class=p>(</span><span class=mi>256</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s1>&#39;relu&#39;</span><span class=p>),</span>
        <span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>layers</span><span class=o>.</span><span class=n>Dropout</span><span class=p>(</span><span class=mf>0.3</span><span class=p>),</span>
        <span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>layers</span><span class=o>.</span><span class=n>BatchNormalization</span><span class=p>(),</span>
        <span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>layers</span><span class=o>.</span><span class=n>Dense</span><span class=p>(</span><span class=mi>128</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s1>&#39;relu&#39;</span><span class=p>),</span>
        <span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>layers</span><span class=o>.</span><span class=n>Dropout</span><span class=p>(</span><span class=mf>0.3</span><span class=p>),</span>
        <span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>layers</span><span class=o>.</span><span class=n>BatchNormalization</span><span class=p>(),</span>
        <span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>layers</span><span class=o>.</span><span class=n>Dense</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s1>&#39;sigmoid&#39;</span><span class=p>,</span> <span class=n>bias_initializer</span><span class=o>=</span><span class=n>bias</span><span class=p>)</span>
    <span class=p>])</span>
    <span class=n>model</span><span class=o>.</span><span class=n>compile</span><span class=p>(</span>
        <span class=n>optimizer</span><span class=o>=</span><span class=s1>&#39;adam&#39;</span><span class=p>,</span>
        <span class=n>loss</span><span class=o>=</span><span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>losses</span><span class=o>.</span><span class=n>BinaryCrossentropy</span><span class=p>(</span><span class=n>from_logits</span><span class=o>=</span><span class=bp>False</span><span class=p>),</span>
        <span class=n>metrics</span><span class=o>=</span><span class=n>METRICS</span>
    <span class=p>)</span>
    <span class=k>return</span> <span class=n>model</span>
</code></pre></div><h3 id=fit-and-run-the-model>Fit and Run the Model</h3><p>To run the model, we have 14 items to ensure {WIP}</p><ul><li><strong>Callbacks:</strong></li><li><strong>Early Stopping:</strong></li><li><strong>Reduce Learning on Plateau</strong></li><li><strong>Accuracy Monitoring:</strong></li><li><strong>Patience:</strong></li><li><strong>Baseline:</strong></li><li><strong>Restore Best Weights:</strong></li><li><strong>History:</strong></li></ul><div class=highlight><pre class=chroma><code class=language-python data-lang=python>
<span class=k>def</span> <span class=nf>run</span><span class=p>(</span>
    <span class=n>train_data</span><span class=p>,</span> <span class=n>val_data</span><span class=p>,</span> <span class=n>feature_columns</span><span class=p>,</span> 
    <span class=n>epochs</span><span class=o>=</span><span class=n>EPOCHS</span><span class=p>,</span> <span class=n>es</span><span class=o>=</span><span class=bp>False</span><span class=p>,</span> <span class=n>rlr</span><span class=o>=</span><span class=bp>False</span><span class=p>,</span> 
    <span class=n>class_weights</span><span class=o>=</span><span class=bp>None</span><span class=p>,</span> <span class=n>initial_bias</span><span class=o>=</span><span class=bp>None</span>
<span class=p>):</span>
    <span class=n>feature_layer</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>layers</span><span class=o>.</span><span class=n>DenseFeatures</span><span class=p>(</span><span class=n>feature_columns</span><span class=p>)</span>
    <span class=n>model</span> <span class=o>=</span> <span class=n>create_silly_model_2</span><span class=p>(</span><span class=n>feature_layer</span><span class=p>,</span> <span class=n>initial_bias</span><span class=p>)</span>

    <span class=n>callbacks</span> <span class=o>=</span> <span class=p>[]</span>
    <span class=k>if</span><span class=p>(</span><span class=n>es</span><span class=p>):</span>
        <span class=n>callbacks</span><span class=o>.</span><span class=n>append</span><span class=p>(</span>
            <span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>callbacks</span><span class=o>.</span><span class=n>EarlyStopping</span><span class=p>(</span>
                <span class=n>monitor</span><span class=o>=</span><span class=s1>&#39;val_auc&#39;</span><span class=p>,</span> <span class=n>min_delta</span><span class=o>=</span><span class=mf>0.00001</span><span class=p>,</span> <span class=n>patience</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span> 
                <span class=n>mode</span><span class=o>=</span><span class=s1>&#39;auto&#39;</span><span class=p>,</span> <span class=n>verbose</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>baseline</span><span class=o>=</span><span class=bp>None</span><span class=p>,</span> <span class=n>restore_best_weights</span><span class=o>=</span><span class=bp>True</span>
            <span class=p>)</span>
        <span class=p>)</span>
    <span class=k>if</span><span class=p>(</span><span class=n>rlr</span><span class=p>):</span>
        <span class=n>callbacks</span><span class=o>.</span><span class=n>append</span><span class=p>(</span>
            <span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>callbacks</span><span class=o>.</span><span class=n>ReduceLROnPlateau</span><span class=p>(</span>
                <span class=n>monitor</span><span class=o>=</span><span class=s1>&#39;val_auc&#39;</span><span class=p>,</span> <span class=n>factor</span><span class=o>=</span><span class=mf>0.5</span><span class=p>,</span> <span class=n>patience</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> 
                <span class=n>min_lr</span><span class=o>=</span><span class=mf>3e-6</span><span class=p>,</span> <span class=n>mode</span><span class=o>=</span><span class=s1>&#39;auto&#39;</span><span class=p>,</span> <span class=n>verbose</span><span class=o>=</span><span class=mi>1</span>
            <span class=p>)</span>
        <span class=p>)</span>

    <span class=n>history</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span>
        <span class=n>train_ds</span><span class=p>,</span> 
        <span class=n>validation_data</span><span class=o>=</span><span class=n>val_ds</span><span class=p>,</span> 
        <span class=n>epochs</span><span class=o>=</span><span class=n>epochs</span><span class=p>,</span> 
        <span class=n>callbacks</span><span class=o>=</span><span class=n>callbacks</span><span class=p>,</span>
        <span class=n>class_weight</span><span class=o>=</span><span class=n>class_weights</span>
    <span class=p>)</span>
    
    <span class=k>return</span> <span class=n>model</span><span class=p>,</span> <span class=n>history</span>
</code></pre></div><div class=highlight><pre class=chroma><code class=language-python data-lang=python><span class=n>model</span><span class=p>,</span> <span class=n>history</span> <span class=o>=</span> <span class=n>run</span><span class=p>(</span>
    <span class=n>train_ds</span><span class=p>,</span> <span class=n>val_ds</span><span class=p>,</span> <span class=n>feature_columns</span><span class=p>,</span> 
    <span class=n>epochs</span><span class=o>=</span><span class=n>EPOCHS</span><span class=p>,</span> <span class=n>es</span><span class=o>=</span><span class=bp>False</span><span class=p>,</span> <span class=n>rlr</span><span class=o>=</span><span class=bp>False</span><span class=p>,</span> 
    <span class=n>class_weights</span><span class=o>=</span><span class=bp>None</span><span class=p>,</span> <span class=n>initial_bias</span><span class=o>=</span><span class=bp>None</span>
<span class=p>)</span>
</code></pre></div><pre><code>Train for 469 steps, validate for 118 steps
Epoch 1/25
469/469 [==============================] - 33s 71ms/step - loss: 0.5749 - tp: 23812.0000 - fp: 68890.0000 - tn: 321252.0000 - fn: 66046.0000 - accuracy: 0.7189 - precision: 0.2569 - recall: 0.2650 - auc: 0.6274 - val_loss: 0.4213 - val_tp: 1147.0000 - val_fp: 647.0000 - val_tn: 96888.0000 - val_fn: 21318.0000 - val_accuracy: 0.8170 - val_precision: 0.6394 - val_recall: 0.0511 - val_auc: 0.7473
Epoch 2/25
469/469 [==============================] - 25s 53ms/step - loss: 0.4222 - tp: 11273.0000 - fp: 9061.0000 - tn: 381081.0000 - fn: 78585.0000 - accuracy: 0.8174 - precision: 0.5544 - recall: 0.1255 - auc: 0.7493 - val_loss: 0.4074 - val_tp: 2598.0000 - val_fp: 1549.0000 - val_tn: 95986.0000 - val_fn: 19867.0000 - val_accuracy: 0.8215 - val_precision: 0.6265 - val_recall: 0.1156 - val_auc: 0.7723
Epoch 3/25
469/469 [==============================] - 25s 53ms/step - loss: 0.4085 - tp: 13544.0000 - fp: 9504.0000 - tn: 380638.0000 - fn: 76314.0000 - accuracy: 0.8212 - precision: 0.5876 - recall: 0.1507 - auc: 0.7710 - val_loss: 0.4031 - val_tp: 3026.0000 - val_fp: 1863.0000 - val_tn: 95672.0000 - val_fn: 19439.0000 - val_accuracy: 0.8225 - val_precision: 0.6189 - val_recall: 0.1347 - val_auc: 0.7784
Epoch 4/25
469/469 [==============================] - 25s 54ms/step - loss: 0.4025 - tp: 14942.0000 - fp: 9834.0000 - tn: 380308.0000 - fn: 74916.0000 - accuracy: 0.8234 - precision: 0.6031 - recall: 0.1663 - auc: 0.7793 - val_loss: 0.4016 - val_tp: 3427.0000 - val_fp: 2158.0000 - val_tn: 95377.0000 - val_fn: 19038.0000 - val_accuracy: 0.8234 - val_precision: 0.6136 - val_recall: 0.1525 - val_auc: 0.7806
Epoch 5/25
469/469 [==============================] - 25s 53ms/step - loss: 0.3985 - tp: 15553.0000 - fp: 10184.0000 - tn: 379958.0000 - fn: 74305.0000 - accuracy: 0.8240 - precision: 0.6043 - recall: 0.1731 - auc: 0.7854 - val_loss: 0.4005 - val_tp: 2993.0000 - val_fp: 1749.0000 - val_tn: 95786.0000 - val_fn: 19472.0000 - val_accuracy: 0.8232 - val_precision: 0.6312 - val_recall: 0.1332 - val_auc: 0.7821
Epoch 6/25
469/469 [==============================] - 25s 54ms/step - loss: 0.3948 - tp: 16272.0000 - fp: 10312.0000 - tn: 379830.0000 - fn: 73586.0000 - accuracy: 0.8252 - precision: 0.6121 - recall: 0.1811 - auc: 0.7905 - val_loss: 0.4004 - val_tp: 3529.0000 - val_fp: 2217.0000 - val_tn: 95318.0000 - val_fn: 18936.0000 - val_accuracy: 0.8237 - val_precision: 0.6142 - val_recall: 0.1571 - val_auc: 0.7820
Epoch 7/25
469/469 [==============================] - 25s 53ms/step - loss: 0.3918 - tp: 16942.0000 - fp: 10669.0000 - tn: 379473.0000 - fn: 72916.0000 - accuracy: 0.8259 - precision: 0.6136 - recall: 0.1885 - auc: 0.7948 - val_loss: 0.4013 - val_tp: 3272.0000 - val_fp: 2037.0000 - val_tn: 95498.0000 - val_fn: 19193.0000 - val_accuracy: 0.8231 - val_precision: 0.6163 - val_recall: 0.1456 - val_auc: 0.7810
Epoch 8/25
469/469 [==============================] - 25s 53ms/step - loss: 0.3889 - tp: 17452.0000 - fp: 10732.0000 - tn: 379410.0000 - fn: 72406.0000 - accuracy: 0.8268 - precision: 0.6192 - recall: 0.1942 - auc: 0.7988 - val_loss: 0.4026 - val_tp: 3409.0000 - val_fp: 2198.0000 - val_tn: 95337.0000 - val_fn: 19056.0000 - val_accuracy: 0.8229 - val_precision: 0.6080 - val_recall: 0.1517 - val_auc: 0.7797
Epoch 9/25
469/469 [==============================] - 25s 52ms/step - loss: 0.3858 - tp: 17965.0000 - fp: 10993.0000 - tn: 379149.0000 - fn: 71893.0000 - accuracy: 0.8273 - precision: 0.6204 - recall: 0.1999 - auc: 0.8030 - val_loss: 0.4044 - val_tp: 3413.0000 - val_fp: 2166.0000 - val_tn: 95369.0000 - val_fn: 19052.0000 - val_accuracy: 0.8232 - val_precision: 0.6118 - val_recall: 0.1519 - val_auc: 0.7782
Epoch 10/25
469/469 [==============================] - 25s 53ms/step - loss: 0.3823 - tp: 18428.0000 - fp: 11131.0000 - tn: 379011.0000 - fn: 71430.0000 - accuracy: 0.8280 - precision: 0.6234 - recall: 0.2051 - auc: 0.8076 - val_loss: 0.4082 - val_tp: 3330.0000 - val_fp: 2146.0000 - val_tn: 95389.0000 - val_fn: 19135.0000 - val_accuracy: 0.8227 - val_precision: 0.6081 - val_recall: 0.1482 - val_auc: 0.7750
Epoch 11/25
469/469 [==============================] - 25s 54ms/step - loss: 0.3787 - tp: 19055.0000 - fp: 11439.0000 - tn: 378703.0000 - fn: 70803.0000 - accuracy: 0.8287 - precision: 0.6249 - recall: 0.2121 - auc: 0.8124 - val_loss: 0.4101 - val_tp: 4147.0000 - val_fp: 3054.0000 - val_tn: 94481.0000 - val_fn: 18318.0000 - val_accuracy: 0.8219 - val_precision: 0.5759 - val_recall: 0.1846 - val_auc: 0.7722
Epoch 12/25
469/469 [==============================] - 25s 53ms/step - loss: 0.3754 - tp: 19808.0000 - fp: 11611.0000 - tn: 378531.0000 - fn: 70050.0000 - accuracy: 0.8299 - precision: 0.6304 - recall: 0.2204 - auc: 0.8165 - val_loss: 0.4142 - val_tp: 3852.0000 - val_fp: 2812.0000 - val_tn: 94723.0000 - val_fn: 18613.0000 - val_accuracy: 0.8215 - val_precision: 0.5780 - val_recall: 0.1715 - val_auc: 0.7701
Epoch 13/25
469/469 [==============================] - 25s 54ms/step - loss: 0.3717 - tp: 20435.0000 - fp: 11942.0000 - tn: 378200.0000 - fn: 69423.0000 - accuracy: 0.8305 - precision: 0.6312 - recall: 0.2274 - auc: 0.8213 - val_loss: 0.4191 - val_tp: 3611.0000 - val_fp: 2664.0000 - val_tn: 94871.0000 - val_fn: 18854.0000 - val_accuracy: 0.8207 - val_precision: 0.5755 - val_recall: 0.1607 - val_auc: 0.7680
Epoch 14/25
469/469 [==============================] - 25s 53ms/step - loss: 0.3678 - tp: 21362.0000 - fp: 12238.0000 - tn: 377904.0000 - fn: 68496.0000 - accuracy: 0.8318 - precision: 0.6358 - recall: 0.2377 - auc: 0.8261 - val_loss: 0.4227 - val_tp: 3710.0000 - val_fp: 2777.0000 - val_tn: 94758.0000 - val_fn: 18755.0000 - val_accuracy: 0.8206 - val_precision: 0.5719 - val_recall: 0.1651 - val_auc: 0.7641
Epoch 15/25
469/469 [==============================] - 25s 53ms/step - loss: 0.3643 - tp: 21929.0000 - fp: 12313.0000 - tn: 377829.0000 - fn: 67929.0000 - accuracy: 0.8328 - precision: 0.6404 - recall: 0.2440 - auc: 0.8301 - val_loss: 0.4265 - val_tp: 3909.0000 - val_fp: 2992.0000 - val_tn: 94543.0000 - val_fn: 18556.0000 - val_accuracy: 0.8204 - val_precision: 0.5664 - val_recall: 0.1740 - val_auc: 0.7630
Epoch 16/25
469/469 [==============================] - 25s 53ms/step - loss: 0.3537 - tp: 24442.0000 - fp: 13295.0000 - tn: 376847.0000 - fn: 65416.0000 - accuracy: 0.8360 - precision: 0.6477 - recall: 0.2720 - auc: 0.8425 - val_loss: 0.4461 - val_tp: 4072.0000 - val_fp: 3445.0000 - val_tn: 94090.0000 - val_fn: 18393.0000 - val_accuracy: 0.8180 - val_precision: 0.5417 - val_recall: 0.1813 - val_auc: 0.7557
Epoch 19/25
469/469 [==============================] - 24s 52ms/step - loss: 0.3496 - tp: 25285.0000 - fp: 13602.0000 - tn: 376540.0000 - fn: 64573.0000 - accuracy: 0.8371 - precision: 0.6502 - recall: 0.2814 - auc: 0.8468 - val_loss: 0.4484 - val_tp: 4476.0000 - val_fp: 3987.0000 - val_tn: 93548.0000 - val_fn: 17989.0000 - val_accuracy: 0.8169 - val_precision: 0.5289 - val_recall: 0.1992 - val_auc: 0.7534
Epoch 20/25
469/469 [==============================] - 25s 52ms/step - loss: 0.3469 - tp: 25787.0000 - fp: 13805.0000 - tn: 376337.0000 - fn: 64071.0000 - accuracy: 0.8378 - precision: 0.6513 - recall: 0.2870 - auc: 0.8500 - val_loss: 0.4579 - val_tp: 4421.0000 - val_fp: 3853.0000 - val_tn: 93682.0000 - val_fn: 18044.0000 - val_accuracy: 0.8175 - val_precision: 0.5343 - val_recall: 0.1968 - val_auc: 0.7518
Epoch 21/25
469/469 [==============================] - 24s 52ms/step - loss: 0.3434 - tp: 26762.0000 - fp: 14046.0000 - tn: 376096.0000 - fn: 63096.0000 - accuracy: 0.8393 - precision: 0.6558 - recall: 0.2978 - auc: 0.8536 - val_loss: 0.4671 - val_tp: 4338.0000 - val_fp: 3838.0000 - val_tn: 93697.0000 - val_fn: 18127.0000 - val_accuracy: 0.8170 - val_precision: 0.5306 - val_recall: 0.1931 - val_auc: 0.7506
Epoch 22/25
469/469 [==============================] - 24s 52ms/step - loss: 0.3399 - tp: 27827.0000 - fp: 14468.0000 - tn: 375674.0000 - fn: 62031.0000 - accuracy: 0.8406 - precision: 0.6579 - recall: 0.3097 - auc: 0.8573 - val_loss: 0.4654 - val_tp: 4735.0000 - val_fp: 4405.0000 - val_tn: 93130.0000 - val_fn: 17730.0000 - val_accuracy: 0.8155 - val_precision: 0.5181 - val_recall: 0.2108 - val_auc: 0.7480
Epoch 23/25
469/469 [==============================] - 25s 53ms/step - loss: 0.3375 - tp: 28330.0000 - fp: 14735.0000 - tn: 375407.0000 - fn: 61528.0000 - accuracy: 0.8411 - precision: 0.6578 - recall: 0.3153 - auc: 0.8597 - val_loss: 0.4783 - val_tp: 4489.0000 - val_fp: 4265.0000 - val_tn: 93270.0000 - val_fn: 17976.0000 - val_accuracy: 0.8147 - val_precision: 0.5128 - val_recall: 0.1998 - val_auc: 0.7460
Epoch 24/25
469/469 [==============================] - 24s 52ms/step - loss: 0.3344 - tp: 29311.0000 - fp: 14883.0000 - tn: 375259.0000 - fn: 60547.0000 - accuracy: 0.8429 - precision: 0.6632 - recall: 0.3262 - auc: 0.8628 - val_loss: 0.4816 - val_tp: 4894.0000 - val_fp: 4764.0000 - val_tn: 92771.0000 - val_fn: 17571.0000 - val_accuracy: 0.8139 - val_precision: 0.5067 - val_recall: 0.2178 - val_auc: 0.7471
Epoch 25/25
469/469 [==============================] - 25s 52ms/step - loss: 0.3317 - tp: 30159.0000 - fp: 15392.0000 - tn: 374750.0000 - fn: 59699.0000 - accuracy: 0.8436 - precision: 0.6621 - recall: 0.3356 - auc: 0.8655 - val_loss: 0.4868 - val_tp: 5103.0000 - val_fp: 5261.0000 - val_tn: 92274.0000 - val_fn: 17362.0000 - val_accuracy: 0.8115 - val_precision: 0.4924 - val_recall: 0.2272 - val_auc: 0.7446
</code></pre><div class=highlight><pre class=chroma><code class=language-python data-lang=python><span class=n>predictions</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>test_ds</span><span class=p>)</span>
<span class=n>submit</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>()</span>
<span class=n>submit</span><span class=p>[</span><span class=s2>&#34;id&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>test_df</span><span class=p>[</span><span class=s2>&#34;id&#34;</span><span class=p>]</span>
<span class=n>submit</span><span class=p>[</span><span class=s1>&#39;target&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>predictions</span>
<span class=n>submit</span><span class=o>.</span><span class=n>to_csv</span><span class=p>(</span><span class=s1>&#39;submission_dl_stratify.csv&#39;</span><span class=p>,</span> <span class=n>index</span><span class=o>=</span><span class=bp>False</span><span class=p>)</span>
</code></pre></div><h2 id=model-performance-and-metrics>Model Performance and Metrics</h2><ul><li>A model is rated through various metrics and the list we saw in the data preparation part. These metrics gives us an opportunity get insight over the model&rsquo;s performance.</li><li>The primary goal of building a model is to avoid overfit over the training data. Achieving a high accuracy on train data almost always result in poor performance over the real data</li><li>That is nothing but the neural network failed to learn the critical patterns hidden deeply inside the dataset.</li><li>Training for longer time will result in overfit. That is control over the number of epochs.</li></ul><p>In this section we shall plot the following metrics across train and validation datasets</p><ul><li>Loss</li><li>AUC, Area Under the Curve</li><li>Precision</li><li>Recall</li></ul><p>Further we shall draw the ROC(Receiver Operating Curve) and observe the model performance from the training history.</p><div class=highlight><pre class=chroma><code class=language-python data-lang=python><span class=kn>import</span> <span class=nn>matplotlib</span> <span class=kn>as</span> <span class=nn>mpl</span>
<span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=kn>as</span> <span class=nn>plt</span>
<span class=n>mpl</span><span class=o>.</span><span class=n>rcParams</span><span class=p>[</span><span class=s1>&#39;figure.figsize&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=p>(</span><span class=mi>15</span><span class=p>,</span> <span class=mi>10</span><span class=p>)</span>
<span class=n>colors</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>rcParams</span><span class=p>[</span><span class=s1>&#39;axes.prop_cycle&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>by_key</span><span class=p>()[</span><span class=s1>&#39;color&#39;</span><span class=p>]</span>
</code></pre></div><div class=highlight><pre class=chroma><code class=language-python data-lang=python><span class=k>def</span> <span class=nf>plot_metrics</span><span class=p>(</span><span class=n>history</span><span class=p>):</span>
    <span class=n>metrics</span> <span class=o>=</span> <span class=p>[</span><span class=s1>&#39;loss&#39;</span><span class=p>,</span> <span class=s1>&#39;auc&#39;</span><span class=p>,</span> <span class=s1>&#39;precision&#39;</span><span class=p>,</span> <span class=s1>&#39;recall&#39;</span><span class=p>]</span>
    
    <span class=k>for</span> <span class=n>n</span><span class=p>,</span> <span class=n>metric</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>metrics</span><span class=p>):</span>
        <span class=n>name</span> <span class=o>=</span> <span class=n>metric</span><span class=o>.</span><span class=n>replace</span><span class=p>(</span><span class=s2>&#34;_&#34;</span><span class=p>,</span> <span class=s2>&#34; &#34;</span><span class=p>)</span><span class=o>.</span><span class=n>capitalize</span><span class=p>()</span>
        <span class=n>plt</span><span class=o>.</span><span class=n>subplot</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=n>n</span><span class=o>+</span><span class=mi>1</span><span class=p>)</span>
        <span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span>
            <span class=n>history</span><span class=o>.</span><span class=n>epoch</span><span class=p>,</span> 
            <span class=n>history</span><span class=o>.</span><span class=n>history</span><span class=p>[</span><span class=n>metric</span><span class=p>],</span> 
            <span class=n>color</span><span class=o>=</span><span class=n>colors</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> 
            <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Train&#39;</span>
        <span class=p>)</span>
        <span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span>
            <span class=n>history</span><span class=o>.</span><span class=n>epoch</span><span class=p>,</span> 
            <span class=n>history</span><span class=o>.</span><span class=n>history</span><span class=p>[</span><span class=s1>&#39;val_&#39;</span> <span class=o>+</span> <span class=n>metric</span><span class=p>],</span> 
            <span class=n>color</span><span class=o>=</span><span class=n>colors</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> 
            <span class=n>linestyle</span><span class=o>=</span><span class=s2>&#34;--&#34;</span><span class=p>,</span> 
            <span class=n>label</span><span class=o>=</span><span class=s1>&#39;val&#39;</span>
        <span class=p>)</span>
        <span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=n>metric</span><span class=o>.</span><span class=n>upper</span><span class=p>())</span>
        <span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Epoch&#39;</span><span class=p>)</span>
        <span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=n>name</span><span class=p>)</span>
        <span class=k>if</span><span class=p>(</span><span class=n>metric</span> <span class=o>==</span> <span class=s1>&#39;loss&#39;</span><span class=p>):</span>
            <span class=n>plt</span><span class=o>.</span><span class=n>ylim</span><span class=p>([</span><span class=mi>0</span><span class=p>,</span> <span class=n>plt</span><span class=o>.</span><span class=n>ylim</span><span class=p>()[</span><span class=mi>1</span><span class=p>]])</span>
        <span class=k>elif</span><span class=p>(</span><span class=n>metric</span> <span class=o>==</span> <span class=s1>&#39;auc&#39;</span><span class=p>):</span>
            <span class=n>plt</span><span class=o>.</span><span class=n>ylim</span><span class=p>([</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>])</span>
        <span class=k>else</span><span class=p>:</span>
            <span class=n>plt</span><span class=o>.</span><span class=n>ylim</span><span class=p>([</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>])</span>
        <span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
        
<span class=n>plot_metrics</span><span class=p>(</span><span class=n>history</span><span class=p>)</span>
</code></pre></div><p><img src=output_35_0.png alt=png></p><h3 id=observations>Observations</h3><p><strong>Loss:</strong><br>Loss of validation dataset to go down, inference: overfitting<br><strong>Area Under the Curve(AUC):</strong><br>AUC of validation dataset to be more than train set, inference: overfitting<br><strong>Precision:</strong><br>Precision of Validation and Train to be similar, inference: overfitting<br><strong>Recall:</strong><br>Recall progression validation set to be along or above the train set: overfitting</p><h2 id=roc---receiver-operating-characteristics>ROC - Receiver Operating Characteristics</h2><p>For a binary classification problems, a ROC curve illustrates the ability of the model to predict the actual.</p><ul><li>It is plotted between True Positive Rate(TPR) and False Positive Rate(FPR)</li><li>TPR is probability of predicting rightly</li><li>FPR is the probability of a false prediction</li><li>ROC&rsquo;s goal is to play as a tool to select optimal models</li></ul><div class=highlight><pre class=chroma><code class=language-python data-lang=python><span class=n>train_predictions</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>train_ds</span><span class=p>)</span>
<span class=n>val_predictions</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>val_ds</span><span class=p>)</span>
</code></pre></div><div class=highlight><pre class=chroma><code class=language-python data-lang=python><span class=kn>from</span> <span class=nn>sklearn</span> <span class=kn>import</span> <span class=n>metrics</span>

<span class=k>def</span> <span class=nf>roc</span><span class=p>(</span><span class=n>name</span><span class=p>,</span> <span class=n>labels</span><span class=p>,</span> <span class=n>predictions</span><span class=p>,</span> <span class=o>**</span><span class=n>kwargs</span><span class=p>):</span>
    <span class=n>fp</span><span class=p>,</span> <span class=n>tp</span><span class=p>,</span> <span class=n>_</span> <span class=o>=</span> <span class=n>metrics</span><span class=o>.</span><span class=n>roc_curve</span><span class=p>(</span><span class=n>labels</span><span class=p>,</span> <span class=n>predictions</span><span class=p>)</span>
    
    <span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=mi>100</span><span class=o>*</span><span class=n>fp</span><span class=p>,</span> <span class=mi>100</span><span class=o>*</span><span class=n>tp</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=n>name</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=o>**</span><span class=n>kwargs</span><span class=p>)</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;False Positives [%]&#39;</span><span class=p>)</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;True Positives [%]&#39;</span><span class=p>)</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>xlim</span><span class=p>([</span><span class=o>-</span><span class=mf>0.5</span><span class=p>,</span> <span class=mi>110</span><span class=p>])</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>ylim</span><span class=p>([</span><span class=mi>1</span><span class=p>,</span> <span class=mi>110</span><span class=p>])</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=bp>True</span><span class=p>)</span>
    <span class=n>ax</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>gca</span><span class=p>()</span>
    <span class=n>ax</span><span class=o>.</span><span class=n>set_aspect</span><span class=p>(</span><span class=s1>&#39;equal&#39;</span><span class=p>)</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>


</code></pre></div><div class=highlight><pre class=chroma><code class=language-python data-lang=python><span class=n>roc</span><span class=p>(</span><span class=s1>&#39;Train&#39;</span><span class=p>,</span> <span class=n>y_train</span><span class=p>,</span> <span class=n>train_predictions</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=n>colors</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span>
<span class=n>roc</span><span class=p>(</span><span class=s1>&#39;Validate&#39;</span><span class=p>,</span> <span class=n>y_val</span><span class=p>,</span> <span class=n>val_predictions</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=n>colors</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>linestyle</span><span class=o>=</span><span class=s1>&#39;--&#39;</span><span class=p>)</span>
</code></pre></div><p><img src=output_40_0.png alt=png></p><h2 id=intervention-1-early-stopping-and-reduce-learning-rate-on-plateau>Intervention 1: Early Stopping and Reduce Learning Rate on Plateau</h2><p>Let us try to fix the overfitting problem by</p><ul><li>Early stop the training and</li><li>Reduce learning rate when a plateau is encountered</li></ul><div class=highlight><pre class=chroma><code class=language-python data-lang=python><span class=n>model</span><span class=p>,</span> <span class=n>history</span> <span class=o>=</span> <span class=n>run</span><span class=p>(</span>
    <span class=n>train_ds</span><span class=p>,</span> <span class=n>val_ds</span><span class=p>,</span> <span class=n>feature_columns</span><span class=p>,</span> 
    <span class=n>epochs</span><span class=o>=</span><span class=n>EPOCHS</span><span class=p>,</span> <span class=n>es</span><span class=o>=</span><span class=bp>True</span><span class=p>,</span> <span class=n>rlr</span><span class=o>=</span><span class=bp>True</span><span class=p>,</span> 
    <span class=n>class_weights</span><span class=o>=</span><span class=bp>None</span><span class=p>,</span> <span class=n>initial_bias</span><span class=o>=</span><span class=bp>None</span>
<span class=p>)</span>
</code></pre></div><pre><code>Train for 469 steps, validate for 118 steps
Epoch 1/25
469/469 [==============================] - 32s 69ms/step - loss: 0.4544 - tp: 9475.0000 - fp: 13661.0000 - tn: 376481.0000 - fn: 80383.0000 - accuracy: 0.8041 - precision: 0.4095 - recall: 0.1054 - auc: 0.6907 - val_loss: 0.4179 - val_tp: 1485.0000 - val_fp: 963.0000 - val_tn: 96572.0000 - val_fn: 20980.0000 - val_accuracy: 0.8171 - val_precision: 0.6066 - val_recall: 0.0661 - val_auc: 0.7522
Epoch 2/25
469/469 [==============================] - 25s 54ms/step - loss: 0.4141 - tp: 11979.0000 - fp: 8799.0000 - tn: 381343.0000 - fn: 77879.0000 - accuracy: 0.8194 - precision: 0.5765 - recall: 0.1333 - auc: 0.7599 - val_loss: 0.4051 - val_tp: 3483.0000 - val_fp: 2389.0000 - val_tn: 95146.0000 - val_fn: 18982.0000 - val_accuracy: 0.8219 - val_precision: 0.5932 - val_recall: 0.1550 - val_auc: 0.7738
Epoch 3/25
469/469 [==============================] - 25s 54ms/step - loss: 0.4047 - tp: 14024.0000 - fp: 9794.0000 - tn: 380348.0000 - fn: 75834.0000 - accuracy: 0.8216 - precision: 0.5888 - recall: 0.1561 - auc: 0.7756 - val_loss: 0.4023 - val_tp: 3741.0000 - val_fp: 2534.0000 - val_tn: 95001.0000 - val_fn: 18724.0000 - val_accuracy: 0.8228 - val_precision: 0.5962 - val_recall: 0.1665 - val_auc: 0.7784
Epoch 4/25
468/469 [============================&gt;.] - ETA: 0s - loss: 0.4000 - tp: 15217.0000 - fp: 10236.0000 - tn: 379266.0000 - fn: 74513.0000 - accuracy: 0.8232 - precision: 0.5978 - recall: 0.1696 - auc: 0.7830
Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
469/469 [==============================] - 26s 56ms/step - loss: 0.3999 - tp: 15238.0000 - fp: 10252.0000 - tn: 379890.0000 - fn: 74620.0000 - accuracy: 0.8232 - precision: 0.5978 - recall: 0.1696 - auc: 0.7830 - val_loss: 0.4007 - val_tp: 3713.0000 - val_fp: 2416.0000 - val_tn: 95119.0000 - val_fn: 18752.0000 - val_accuracy: 0.8236 - val_precision: 0.6058 - val_recall: 0.1653 - val_auc: 0.7809
Epoch 5/25
469/469 [==============================] - 25s 52ms/step - loss: 0.3946 - tp: 16660.0000 - fp: 10785.0000 - tn: 379357.0000 - fn: 73198.0000 - accuracy: 0.8250 - precision: 0.6070 - recall: 0.1854 - auc: 0.7909 - val_loss: 0.4006 - val_tp: 3706.0000 - val_fp: 2429.0000 - val_tn: 95106.0000 - val_fn: 18759.0000 - val_accuracy: 0.8234 - val_precision: 0.6041 - val_recall: 0.1650 - val_auc: 0.7809
Epoch 6/25
468/469 [============================&gt;.] - ETA: 0s - loss: 0.3920 - tp: 17201.0000 - fp: 10941.0000 - tn: 378561.0000 - fn: 72529.0000 - accuracy: 0.8258 - precision: 0.6112 - recall: 0.1917 - auc: 0.7949Restoring model weights from the end of the best epoch.
469/469 [==============================] - 25s 53ms/step - loss: 0.3919 - tp: 17227.0000 - fp: 10959.0000 - tn: 379183.0000 - fn: 72631.0000 - accuracy: 0.8259 - precision: 0.6112 - recall: 0.1917 - auc: 0.7949 - val_loss: 0.4014 - val_tp: 3786.0000 - val_fp: 2501.0000 - val_tn: 95034.0000 - val_fn: 18679.0000 - val_accuracy: 0.8235 - val_precision: 0.6022 - val_recall: 0.1685 - val_auc: 0.7800
Epoch 00006: early stopping
</code></pre><h2 id=plot-metrics-loss-vs-auc-vs-precision-vs-recall>Plot Metrics: Loss vs AUC vs Precision vs Recall</h2><div class=highlight><pre class=chroma><code class=language-python data-lang=python><span class=n>plot_metrics</span><span class=p>(</span><span class=n>history</span><span class=p>)</span>
</code></pre></div><p><img src=output_44_0.png alt=png></p><h3 id=observations-1>Observations</h3><p><strong>Loss:</strong><br>Loss of validation dataset got better compared to earlier, inference: overfitting is addressed to some extent<br><strong>Area Under the Curve(AUC):</strong><br>AUC of validation dataset is increased compared to earlier, inference: overfitting is addressed to some extent<br><strong>Precision:</strong><br>No significant change to precision, inference: overfitting<br><strong>Recall:</strong><br>Recall of train and validation set are overalapping: overfitting</p><div class=highlight><pre class=chroma><code class=language-python data-lang=python><span class=n>train_predictions_es_rlr</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>train_ds</span><span class=p>)</span>
<span class=n>val_predictions_es_rlr</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>val_ds</span><span class=p>)</span>
</code></pre></div><h3 id=roc-comparison>ROC comparison</h3><p>Let us compare the baseline model results with the model having intervention of Early Stopping and RLR</p><div class=highlight><pre class=chroma><code class=language-python data-lang=python>
<span class=n>roc</span><span class=p>(</span><span class=s1>&#39;Train Baseline&#39;</span><span class=p>,</span> <span class=n>y_train</span><span class=p>,</span> <span class=n>train_predictions</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=n>colors</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span>
<span class=n>roc</span><span class=p>(</span><span class=s1>&#39;Validate Baseline&#39;</span><span class=p>,</span> <span class=n>y_val</span><span class=p>,</span> <span class=n>val_predictions</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=n>colors</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>linestyle</span><span class=o>=</span><span class=s1>&#39;--&#39;</span><span class=p>)</span>
<span class=n>roc</span><span class=p>(</span><span class=s1>&#39;Train [ES, RLR]&#39;</span><span class=p>,</span> <span class=n>y_train</span><span class=p>,</span> <span class=n>train_predictions_es_rlr</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=n>colors</span><span class=p>[</span><span class=mi>1</span><span class=p>])</span>
<span class=n>roc</span><span class=p>(</span><span class=s1>&#39;Validate [ES, RLR]&#39;</span><span class=p>,</span> <span class=n>y_val</span><span class=p>,</span> <span class=n>val_predictions_es_rlr</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=n>colors</span><span class=p>[</span><span class=mi>1</span><span class=p>],</span> <span class=n>linestyle</span><span class=o>=</span><span class=s1>&#39;--&#39;</span><span class=p>)</span>
</code></pre></div><p><img src=output_48_0.png alt=png></p><h2 id=intervention-2-class-weights-and-initial-bias>Intervention 2: Class Weights and Initial Bias</h2><p>Let us try to fix further the overfitting problem by</p><ul><li>Incorporating Class Weights and</li><li>Initial Bias</li></ul><div class=highlight><pre class=chroma><code class=language-python data-lang=python><span class=n>model</span><span class=p>,</span> <span class=n>history</span> <span class=o>=</span> <span class=n>run</span><span class=p>(</span>
    <span class=n>train_ds</span><span class=p>,</span> <span class=n>val_ds</span><span class=p>,</span> <span class=n>feature_columns</span><span class=p>,</span> 
    <span class=n>epochs</span><span class=o>=</span><span class=n>EPOCHS</span><span class=p>,</span> <span class=n>es</span><span class=o>=</span><span class=bp>True</span><span class=p>,</span> <span class=n>rlr</span><span class=o>=</span><span class=bp>True</span><span class=p>,</span> 
    <span class=n>class_weights</span><span class=o>=</span><span class=n>class_weight</span><span class=p>,</span> <span class=n>initial_bias</span><span class=o>=</span><span class=n>initial_bias</span>
<span class=p>)</span>
</code></pre></div><pre><code>Train for 469 steps, validate for 118 steps
Epoch 1/25
469/469 [==============================] - 39s 83ms/step - loss: 0.6565 - tp: 57523.0000 - fp: 135960.0000 - tn: 254182.0000 - fn: 32335.0000 - accuracy: 0.6494 - precision: 0.2973 - recall: 0.6402 - auc: 0.6976 - val_loss: 0.5864 - val_tp: 16562.0000 - val_fp: 35511.0000 - val_tn: 62024.0000 - val_fn: 5903.0000 - val_accuracy: 0.6549 - val_precision: 0.3181 - val_recall: 0.7372 - val_auc: 0.7543
Epoch 2/25
469/469 [==============================] - 25s 53ms/step - loss: 0.5836 - tp: 65473.0000 - fp: 133975.0000 - tn: 256167.0000 - fn: 24385.0000 - accuracy: 0.6701 - precision: 0.3283 - recall: 0.7286 - auc: 0.7593 - val_loss: 0.5675 - val_tp: 16852.0000 - val_fp: 33630.0000 - val_tn: 63905.0000 - val_fn: 5613.0000 - val_accuracy: 0.6730 - val_precision: 0.3338 - val_recall: 0.7501 - val_auc: 0.7741
Epoch 3/25
469/469 [==============================] - 25s 53ms/step - loss: 0.5677 - tp: 66423.0000 - fp: 129345.0000 - tn: 260797.0000 - fn: 23435.0000 - accuracy: 0.6817 - precision: 0.3393 - recall: 0.7392 - auc: 0.7748 - val_loss: 0.5635 - val_tp: 17278.0000 - val_fp: 34884.0000 - val_tn: 62651.0000 - val_fn: 5187.0000 - val_accuracy: 0.6661 - val_precision: 0.3312 - val_recall: 0.7691 - val_auc: 0.7785
Epoch 4/25
467/469 [============================&gt;.] - ETA: 0s - loss: 0.5602 - tp: 66906.0000 - fp: 128032.0000 - tn: 260626.0000 - fn: 22644.0000 - accuracy: 0.6849 - precision: 0.3432 - recall: 0.7471 - auc: 0.7815
Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
469/469 [==============================] - 25s 53ms/step - loss: 0.5601 - tp: 67136.0000 - fp: 128535.0000 - tn: 261607.0000 - fn: 22722.0000 - accuracy: 0.6849 - precision: 0.3431 - recall: 0.7471 - auc: 0.7815 - val_loss: 0.5615 - val_tp: 17298.0000 - val_fp: 34676.0000 - val_tn: 62859.0000 - val_fn: 5167.0000 - val_accuracy: 0.6680 - val_precision: 0.3328 - val_recall: 0.7700 - val_auc: 0.7806
Epoch 5/25
469/469 [==============================] - 25s 53ms/step - loss: 0.5519 - tp: 68210.0000 - fp: 128319.0000 - tn: 261823.0000 - fn: 21648.0000 - accuracy: 0.6876 - precision: 0.3471 - recall: 0.7591 - auc: 0.7886 - val_loss: 0.5612 - val_tp: 16851.0000 - val_fp: 32538.0000 - val_tn: 64997.0000 - val_fn: 5614.0000 - val_accuracy: 0.6821 - val_precision: 0.3412 - val_recall: 0.7501 - val_auc: 0.7812
Epoch 6/25
467/469 [============================&gt;.] - ETA: 0s - loss: 0.5468 - tp: 68500.0000 - fp: 128116.0000 - tn: 260542.0000 - fn: 21050.0000 - accuracy: 0.6881 - precision: 0.3484 - recall: 0.7649 - auc: 0.7929Restoring model weights from the end of the best epoch.
469/469 [==============================] - 25s 53ms/step - loss: 0.5467 - tp: 68740.0000 - fp: 128614.0000 - tn: 261528.0000 - fn: 21118.0000 - accuracy: 0.6881 - precision: 0.3483 - recall: 0.7650 - auc: 0.7929 - val_loss: 0.5629 - val_tp: 17026.0000 - val_fp: 33360.0000 - val_tn: 64175.0000 - val_fn: 5439.0000 - val_accuracy: 0.6767 - val_precision: 0.3379 - val_recall: 0.7579 - val_auc: 0.7807
Epoch 00006: early stopping
</code></pre><div class=highlight><pre class=chroma><code class=language-python data-lang=python><span class=n>plot_metrics</span><span class=p>(</span><span class=n>history</span><span class=p>)</span>
</code></pre></div><p><img src=output_51_0.png alt=png></p><h3 id=observations-2>Observations</h3><p><strong>Loss:</strong><br>Loss increased compared to earlier, inference: overfitting, model degraded<br><strong>Area Under the Curve(AUC):</strong><br>AUC of previous and current intervention remain same, inference: no improvement<br><strong>Precision:</strong><br>Precision decreased from earlier, inference: model degraded<br><strong>Recall:</strong><br>Recall increased: model degraded</p><div class=highlight><pre class=chroma><code class=language-python data-lang=python><span class=n>train_predictions_bias_cws</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>train_ds</span><span class=p>)</span>
<span class=n>val_predictions_bias_cws</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>val_ds</span><span class=p>)</span>
</code></pre></div><div class=highlight><pre class=chroma><code class=language-python data-lang=python><span class=n>roc</span><span class=p>(</span><span class=s1>&#39;Train Baseline&#39;</span><span class=p>,</span> <span class=n>y_train</span><span class=p>,</span> <span class=n>train_predictions</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=n>colors</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span>
<span class=n>roc</span><span class=p>(</span><span class=s1>&#39;Validate Baseline&#39;</span><span class=p>,</span> <span class=n>y_val</span><span class=p>,</span> <span class=n>val_predictions</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=n>colors</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>linestyle</span><span class=o>=</span><span class=s1>&#39;--&#39;</span><span class=p>)</span>
<span class=n>roc</span><span class=p>(</span><span class=s1>&#39;Train [ES, RLR]&#39;</span><span class=p>,</span> <span class=n>y_train</span><span class=p>,</span> <span class=n>train_predictions_es_rlr</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=n>colors</span><span class=p>[</span><span class=mi>1</span><span class=p>])</span>
<span class=n>roc</span><span class=p>(</span><span class=s1>&#39;Validate [ES, RLR]&#39;</span><span class=p>,</span> <span class=n>y_val</span><span class=p>,</span> <span class=n>val_predictions_es_rlr</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=n>colors</span><span class=p>[</span><span class=mi>1</span><span class=p>],</span> <span class=n>linestyle</span><span class=o>=</span><span class=s1>&#39;--&#39;</span><span class=p>)</span>
<span class=n>roc</span><span class=p>(</span><span class=s1>&#39;Train [ES, RLR, BIAS, IniWts]&#39;</span><span class=p>,</span> <span class=n>y_train</span><span class=p>,</span> <span class=n>train_predictions_bias_cws</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=n>colors</span><span class=p>[</span><span class=mi>2</span><span class=p>])</span>
<span class=n>roc</span><span class=p>(</span><span class=s1>&#39;Validate [ES, RLR, BIAS, IniWts]&#39;</span><span class=p>,</span> <span class=n>y_val</span><span class=p>,</span> <span class=n>val_predictions_bias_cws</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=n>colors</span><span class=p>[</span><span class=mi>2</span><span class=p>],</span> <span class=n>linestyle</span><span class=o>=</span><span class=s1>&#39;--&#39;</span><span class=p>)</span>
</code></pre></div><p><img src=output_54_0.png alt=png></p><h2 id=inference-of-interventions>Inference of Interventions</h2><p>Intervention 1 improved the model but intervention 2 did not make any significant change to the model performance.</p><div class=highlight><pre class=chroma><code class=language-python data-lang=python><span class=n>predictions</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>test_ds</span><span class=p>)</span>
<span class=n>submit</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>()</span>
<span class=n>submit</span><span class=p>[</span><span class=s2>&#34;id&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>test_df</span><span class=p>[</span><span class=s2>&#34;id&#34;</span><span class=p>]</span>
<span class=n>submit</span><span class=p>[</span><span class=s1>&#39;target&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>predictions</span>
<span class=n>submit</span><span class=o>.</span><span class=n>to_csv</span><span class=p>(</span><span class=s1>&#39;submission_dl_final.csv&#39;</span><span class=p>,</span> <span class=n>index</span><span class=o>=</span><span class=bp>False</span><span class=p>)</span>
</code></pre></div></article></div><nav class="docs-toc d-none d-xl-block col-xl-4" aria-label="Secondary navigation"><div class=page-links><h3>On this page</h3><nav id=TableOfContents><ul><li><ul><li><a href=#objective>Objective</a></li></ul></li><li><a href=#pre-processing>Pre-Processing</a><ul><li><a href=#read-data>Read Data</a></li><li><a href=#constants>Constants</a></li></ul></li><li><a href=#understanding-the-features>Understanding the Features</a><ul><li><a href=#dealing-with-missing-data>Dealing with Missing Data</a></li></ul></li><li><a href=#bias-and-class-weights>Bias and Class Weights</a><ul><li><a href=#initial-bias>Initial Bias</a></li><li><a href=#class-weights>Class Weights</a></li></ul></li><li><a href=#stratified-split-of-train-and-validation-data>Stratified Split of Train and Validation Data</a></li><li><a href=#tensorflow-2---feature-columns>Tensorflow 2 - Feature Columns</a></li><li><a href=#one-hot-encoding>One Hot Encoding</a></li><li><a href=#embeddings>Embeddings</a><ul><li><a href=#numeric-columns>Numeric Columns</a></li><li><a href=#random-decisions>Random Decisions</a></li><li><a href=#data-preparation>Data Preparation</a></li></ul></li><li><a href=#model-training-and-prediction>Model, Training and Prediction</a><ul><li><a href=#fit-and-run-the-model>Fit and Run the Model</a></li></ul></li><li><a href=#model-performance-and-metrics>Model Performance and Metrics</a><ul><li><a href=#observations>Observations</a></li></ul></li><li><a href=#roc---receiver-operating-characteristics>ROC - Receiver Operating Characteristics</a></li><li><a href=#intervention-1-early-stopping-and-reduce-learning-rate-on-plateau>Intervention 1: Early Stopping and Reduce Learning Rate on Plateau</a></li><li><a href=#plot-metrics-loss-vs-auc-vs-precision-vs-recall>Plot Metrics: Loss vs AUC vs Precision vs Recall</a><ul><li><a href=#observations-1>Observations</a></li><li><a href=#roc-comparison>ROC comparison</a></li></ul></li><li><a href=#intervention-2-class-weights-and-initial-bias>Intervention 2: Class Weights and Initial Bias</a><ul><li><a href=#observations-2>Observations</a></li></ul></li><li><a href=#inference-of-interventions>Inference of Interventions</a></li></ul></nav></div></nav></div></div></div><footer class="footer text-muted"><div class=container><div class=row><div class="col-lg-8 order-last order-lg-first"><ul class=list-inline><li class=list-inline-item>Copyright 2021 <a href=https://www.gowrishankar.info/>GowriShankar.info</a> All rights reserved</li></ul></div><div class="col-lg-8 order-first order-lg-last text-lg-right"><ul class=list-inline></ul></div></div></div></footer><script src=https://www.gowrishankar.info/main.f6b484f556ad1f3bcf6061082139a2f21fa759f13930c39a25fe4a9f78f35e64122c2d86dffd56e67b292dabbda4095d8077194f196e0e348441c106a9f3d40e.js integrity="sha512-9rSE9VatHzvPYGEIITmi8h+nWfE5MMOaJf5Kn3jzXmQSLC2G3/1W5nspLau9pAldgHcZTxluDjSEQcEGqfPUDg==" crossorigin=anonymous defer></script><script src=https://www.gowrishankar.info/index.min.7a602ace1becaf60dc69027361aa7b13a225462f6639889a37f19953d6b8927cd3940da9251c0d016bebf2fb65357d9a23de4dd04e817f627f2902a88348b45c.js integrity="sha512-emAqzhvsr2DcaQJzYap7E6IlRi9mOYiaN/GZU9a4knzTlA2pJRwNAWvr8vtlNX2aI95N0E6Bf2J/KQKog0i0XA==" crossorigin=anonymous defer></script></body></html>